<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=Edge"><meta http-equiv=permissions-policy content="interest-cohort=()"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#2b7bb5"><meta name=copyright content="Copyright (c)2022 Erik McClure"><meta name=keywords content="games,music,code,erik mcclure,erikmcclure,aurora theory,sweetie bot,discord,feathergui,black sphere studios,tinyoal,upatch"><meta name=robots content="index,follow"><meta name=googlebot content="index,follow"><meta name=google-site-verification content="Oxb2ia8HjcHLXlvstA8xPpQO3BO_y15Ds2Ia-feq1MQ"><meta name=generator content="Hugo 0.62.2"><link rel=canonical href=https://erikmcclure.com/blog/><link rel=apple-touch-icon href=https://erikmcclure.com/favicon.ico><link rel="shortcut icon" type=image/x-icon href=https://erikmcclure.com/favicon.ico><link rel=stylesheet href=https://erikmcclure.com/css/main.css><link rel=stylesheet href=https://erikmcclure.com/css/prism.css rel=stylesheet><link rel=stylesheet href=https://erikmcclure.com/css/katex.min.css rel=stylesheet><link rel=stylesheet href=https://erikmcclure.com/css/font-awesome.min.css><link rel=alternate type=application/rss+xml title="Erik McClure - RSS" href=https://erikmcclure.com/index.xml><meta property="og:type" content="website"><title>Blogs - Erik McClure</title><meta property="og:title" content="Blogs - Erik McClure"><meta name=twitter:title content="Blogs - Erik McClure"><meta itemprop=name content="Blogs - Erik McClure"><meta name=description content="Applied mathematician and software architect who occasionally writes music."><meta property="og:description" content="Applied mathematician and software architect who occasionally writes music."><meta name=twitter:description content="Applied mathematician and software architect who occasionally writes music."><meta itemprop=description content="Applied mathematician and software architect who occasionally writes music."><meta property="og:url" content="https://erikmcclure.com/"><meta property="og:site_name" content="Erik McClure"><meta property="og:image" content="https://erikmcclure.com/img/avatar.png"><meta property="og:locale" content="en-US"><meta property="article:author" content="Erik McClure"><meta name=twitter:card content="summary"><meta name=twitter:site content="@erikmcclure0173"><meta name=twitter:creator content="@erikmcclure0173"><meta name=twitter:image content="https://erikmcclure.com/img/avatar.png"><meta name=twitter:dnt content="on"><link href=https://plus.google.com/104896885003230920472 rel=publisher><meta itemprop=image content="https://erikmcclure.com/img/avatar.png"><meta name=last-updated content="20220702-02:36:00.000"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-63026815-3"></script><script defer src=https://erikmcclure.com/syntax-prism.js></script><script defer src=https://erikmcclure.com/katex.min.js></script><script defer src=https://erikmcclure.com/mathtex-script-type.min.js></script><script defer src=https://erikmcclure.com/auto-render.min.js></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-63026815-3');</script></head><body><div id=container><header><nav><ul><li><a href=/blog/ title=Blog><i class="fa fa-book fa-fw fa-lg"></i>&nbsp;<p>Blog</p></a></li><li><a href=/projects/ title=Projects><i class="fa fa-briefcase fa-fw fa-lg"></i>&nbsp;<p>Projects</p></a></li><li><a href=https://erikmcclure.bandcamp.com title=Bandcamp><i class="fa fa-bandcamp fa-fw fa-lg"></i>&nbsp;<p>Bandcamp</p></a></li><li><a href=https://github.com/erikmcclure title=Github><i class="fa fa-github fa-fw fa-lg"></i>&nbsp;<p>Github</p></a></li><li><a href=https://twitter.com/erikmcclure0173 title=Twitter><i class="fa fa-twitter fa-fw fa-lg"></i>&nbsp;<p>Twitter</p></a></li><li><a href=/web/ title=Websites><i class="fa fa-globe fa-fw fa-lg"></i>&nbsp;<p>Websites</p></a></li></ul></nav><div class=dim><h1>Erik McClure</h1></div></header><main class=blog><section><article><h4><a href=/blog/windows-malloc-implementation-is-a-trash-fire/>The Windows malloc() Implementation Is A Trash Fire</a></h4><hr><div class=padding><p>I am currently porting an experimental language to Windows. This experimental language was built in C++ with LLVM, and relies heavily on GCC extensions like VLAs and <a href=https://gcc.gnu.org/onlinedocs/gcc-3.1.1/gcc/Statement-Exprs.html>Compound Statement Expressions</a>, which basically made it impossible to build with MSVC (although I have a truly horrifying idea I may attempt later). Luckily, you can now build things on Windows with Clang, which solves a lot of problems. However, <code>clang-cl</code> simply compiles the code - it still uses the Microsoft C++ headers and links to the Microsoft C++ runtime. This is a good thing, because it ensures maximum compatibility with win32 APIs and other Windows executables.</p><p>Unfortunately, it also means you get the Windows <code>malloc()</code> implementation from MSVCRT (specifically, it's statically linking with the CRT shipped with Visual Studio), which is quite possibly one of the worst piles of rotten garbage ever compiled in the history of C. I learned how to program, like many people did, by doing indie game dev. Like many people, I never released a single game, but I did write a bunch of code which now lies forgotten in lost GitHub repositories. I was taught that to allocate memory was to summon death itself to ruin your performance. A single call to <code>malloc()</code> during any frame is likely to render your game unplayable. Any sort of allocations that needed to happen with any regularity required writing a custom, purpose-built allocator, usually either a fixed-size block allocator using a freelist, or a greedy allocator freed after the level ended. Even more optimization could be made by using thread-local storage, to maintain thread-specific allocators without ever needing to waste time on concurrency.</p><p>It turns out you don't actually need any of this on Linux. You can basically <code>malloc()</code> whatever you want (within reason) and it'll be surprisingly fast.</p><p>LLVM was built for Linux - or rather, it was built to work for Mac OSX, which is POSIX compliant and looks like a Linux system if you squint. Most optimizations are designed to make it go fast on Mac or Linux. Since it's a compiler, it makes a lot of tiny allocations, because it basically represents control flow as a gigantic digraph. I actually thought it used a custom allocator for allocating these tiny nodes, because that's what I would've done, but in reality, it just calls <code>new</code> everywhere and lets the Linux <code>malloc()</code> implementation deal with it. The reason I care is because this experimental language I'm working on needs to JIT its core library when booting up - it takes about <strong>1.1 seconds</strong> to do this on Linux, and <strong>7 seconds</strong> on Windows.</p><p>At first, I thought this inefficiency came from this experimental language utilizing <code>std::unordered_map</code> everywhere, since this allocates a new chunk of memory for every single item to ensure iterator stability, and is well known for being incredibly inefficient compared to basically any other hash implementation. I substituted this with Google's <a href=https://abseil.io/docs/cpp/guides/container>Abseil <code>flat_hash_map</code> implementation</a>, and achieved an impressive 2x speedup on Windows, dropping the startup time to 4 seconds. Pretty good, and in line with what I expected. Can you guess what the corresponding Linux speedup was?</p><p><strong>Nothing.</strong></p><p>Literally. <strong>Fucking.</strong> <em><strong>NOTHING.</strong></em></p><p>We tested this both on my WSL instance on Windows and a native NixOS desktop, with identical results. Deciding to forge on ahead, I found another inefficient area of the compiler that was needlessly allocating an entire vector to support bignum types, even though none of the tests ever actually used this, so the vector ended up only holding a single integer. I changed it to skip the vector if there was only 1 element. This cut another second from Windows. It appeared to either do nothing on Linux, or somehow made it slightly slower. Worse, based on my profiler analysis, I was running out of stuff outside of LLVM to optimize - the remaining time was mostly LLVM.</p><p>Okay, fuck it, this is clearly an allocator issue, and incidentally, some game developers had started using LLVM for&mldr; some reason, and of course, most games work on Windows, so they needed LLVM to be fast on Windows. They introduced <a href=https://github.com/llvm/llvm-project/blob/c92056d038812c23800131892bee48abb2de7ca0/llvm/lib/Support/CMakeLists.txt#L78>a <em>very</em> janky way</a> of replacing <code>malloc()</code> in LLVM, which I kinda had to hack into a custom <code>vcpkg</code> fork to make it work with my dependency handling, but it seemed to work!</p><p>Except it made LLVM crash.</p><p>It turns out that if you replace <code>malloc()</code> with either <code>rpmalloc</code> or <code>mimalloc</code>, the windows kernel would <strong>sometimes</strong> trigger a debug break instruction while inside <code>std::recursive_mutex</code>, but only if you are JITing code. This happens even if you disable threading in LLVM. At first I thought this was some kind of ABI mismatch (since <a href=https://github.com/llvm/llvm-project/commit/7aaff8fd2da2812a2b3cbc8a41af29774b10a7d6>this has happened before</a>), but no amount of tweaking things to match up fixed the issue. I spoke with a personal friend of mine who happens to work at Apple on LLVM, and they suspect this is a kernel sanity check intended to catch potential deadlocks, maybe because the critical section isn't re-entrant and something screwed up. However, this was inside of a <code>std::recursive_mutex</code> implementation, so&mldr; it should be re-entrant, by definition. There may simply be a race-condition or implementation error somewhere inside LLVM, but I'm really not in the mood to debug extremely arcane multithreading issues in LLVM.</p><p>So, instead, I did the worst hack of my entire life by replacing the efficient <code>std::recursive_mutex</code> implementation that used critical sections with an extremely inefficient re-entrant spinlock.</p><p>This actually worked, and instantly made the startup time on windows approximately <strong>1.2 seconds</strong>, now within the realm of the Linux start times. The <strong>fucking Windows allocator</strong> was the source of all of my performance problems <em>the entire time</em>. <a href=https://reviews.llvm.org/p/aganea/>aganea</a>, who has my undying gratitude for taking over the task of <a href=https://reviews.llvm.org/D70378>unfucking the catastrophic trainwreck that was LLD</a>, happens to also be the one who <a href=https://reviews.llvm.org/D71786>introduced the method of patching LLVM's allocator</a>. Sadly, it seems whatever they were using LLVM for did not involve JITing code, or may have used a different method, as nobody seems to have run into this problem except me.</p><p>The best part about this whole fiasco is that mimalloc <a href=https://github.com/microsoft/mimalloc>was developed by Microsoft</a> for Microsoft services because of how slow Microsoft's own MSVCRT <code>malloc()</code> was. So this entire time I've been trying to replace Microsoft's <code>malloc()</code> with Microsoft's other <code>malloc()</code> because Microsoft's <code>malloc()</code> was too slow for Microsoft. For some insane reason, mimalloc is not shipped in Visual Studio, not even as something that you have to opt-in to (in case there's some backwards compatibility concern). Microsoft's instructions provide <code>operator new</code> overloads instead of actually integrating this with <em>their own compiler</em> despite being nearly <strong>an order of magnitude faster</strong> in rapid small allocation scenarios!</p><p>So, at this point, we have learned three things: the Windows allocator is a complete trash fire, Microsoft invented an alternative to their own allocator but refuse to provide it as an alternative, and there's clearly some kind of race condition in LLVM's JIT in certain edge cases related to the usage of mutexes on Windows. If someone wants to try to reproduce this and file a proper bug on LLVM, go ahead, but it would take days to distill a minimal example for this and I honestly have better things to do right now. The inefficient spinlock doesn't matter when threading is disabled because it has no contention, and having threading enabled does not appear to actually make my use-case go any faster anyway, for whatever reason.</p><p>Everything is broken and I am too tired to do anything but contribute another obscene hack on top of this pile of cards we have built modern civilization on.</p></div><hr><time itemprop=datePublished pubdate=pubdate datetime=2022-07-02T02:36:00+00:00><i class="fa fa-clock-o fa-fw"></i>&nbsp;Published on <a href=https://erikmcclure.com/blog/windows-malloc-implementation-is-a-trash-fire/>July 2, 2022 at 2:36am</a></time><aside><a href=/blog/windows-malloc-implementation-is-a-trash-fire/#comments><i class="fa fa-comments-o fa-fw"></i>&nbsp;0 comments</a></aside><aside><i class="fa fa-share-square-o fa-fw"></i>&nbsp;share:<ul><li><a href="javascript:window.open('https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ferikmcclure.com%2fblog%2fwindows-malloc-implementation-is-a-trash-fire%2f','popup','width=600,height=400');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" d="M16.75 9H13.5V7a1 1 0 011-1h2V3H14a4 4 0 00-4 4V9H8v3h2v9h3.5V12H16z"/></svg></a><li><a href="javascript:window.open('https://twitter.com/intent/tweet?text=The%20Windows%20malloc%28%29%20Implementation%20Is%20A%20Trash%20Fire&url=https%3a%2f%2ferikmcclure.com%2fblog%2fwindows-malloc-implementation-is-a-trash-fire%2f','popup','width=600,height=256');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" opacity="0" d="M0 0h24v24H0z"/><path class="st0" d="M23.643 4.937c-.835.37-1.732.62-2.675.733.962-.576 1.7-1.49 2.048-2.578-.9.534-1.897.922-2.958 1.13-.85-.904-2.06-1.47-3.4-1.47-2.572.0-4.658 2.086-4.658 4.66.0.364.042.718.12 1.06-3.873-.195-7.304-2.05-9.602-4.868-.4.69-.63 1.49-.63 2.342.0 1.616.823 3.043 2.072 3.878-.764-.025-1.482-.234-2.11-.583v.06c0 2.257 1.605 4.14 3.737 4.568-.392.106-.803.162-1.227.162-.3.0-.593-.028-.877-.082.593 1.85 2.313 3.198 4.352 3.234-1.595 1.25-3.604 1.995-5.786 1.995-.376.0-.747-.022-1.112-.065 2.062 1.323 4.51 2.093 7.14 2.093 8.57.0 13.255-7.098 13.255-13.254.0-.2-.005-.402-.014-.602.91-.658 1.7-1.477 2.323-2.41z"/></svg></a></li><li><a href="javascript:window.open('https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ferikmcclure.com%2fblog%2fwindows-malloc-implementation-is-a-trash-fire%2f','popup','width=700,height=380');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><rect class="st0" height="11" width="4" x="3" y="9"/><circle class="st0" cx="5" cy="5" r="2"/><path class="st0" d="M16.5 8.25A4.47251 4.47251.0 0013 9.95343V9H9V20h4V13a2 2 0 014 0v7h4V12.75a4.5 4.5.0 00-4.5-4.5z"/></svg></a></li><li><a href="javascript:window.open('https://plus.google.com/share?app=110&url=https%3a%2f%2ferikmcclure.com%2fblog%2fwindows-malloc-implementation-is-a-trash-fire%2f','popup','width=400,height=380');"><svg xmlns="http://www.w3.org/2000/svg" viewBox="4 2 52.6934 50.6934" class="icon-img" height="24"><style>.st0{fill:#666}</style><g><path class="st0" d="M19.6671 25.7867c-.0075 1.7935.0 3.5869.0076 5.3803 3.0067.098 6.0208.0527 9.0275.098-1.3262 6.6689-10.3989 8.8315-15.199 4.4761C8.5674 31.9206 8.801 23.5412 13.9327 19.992c3.5869-2.8635 8.6884-2.1552 12.2752.324 1.4092-1.3036 2.7278-2.6977 4.0013-4.1445-2.984-2.3812-6.6462-4.0767-10.5421-3.8958-8.1307-.2713-15.6059 6.8497-15.7415 14.9805-.52 6.6462 3.8506 13.1644 10.0222 15.5155 6.1489 2.3661 14.031.7535 17.957-4.77 2.5922-3.4889 3.1498-7.98 2.8484-12.1999C29.7194 25.7641 24.6933 25.7716 19.6671 25.7867z"/><path class="st0" d="M49.0704 25.7641c-.0151-1.4996-.0226-3.0067-.0301-4.5062-1.4996.0-2.9916.0-4.4836.0-.0151 1.4996-.0301 2.9991-.0377 4.5062-1.5071.0075-3.0067.0151-4.5062.0302.0 1.4995.0 2.9915.0 4.4836 1.4995.0151 3.0066.0302 4.5062.0452.0151 1.4996.0151 2.9991.0302 4.4987 1.4996.0 2.9916.0 4.4911.0.0075-1.4996.015-2.9991.0301-4.5062 1.5071-.0151 3.0067-.0226 4.5062-.0377.0-1.4921.0-2.9916.0-4.4836C52.0771 25.7792 50.57 25.7792 49.0704 25.7641z"/></g></svg></a></li></ul></aside></article><article><h4><a href=/blog/camp-vista/>Camp Vista - Growing Up Next To Microsoft</a></h4><hr><div class=padding><p>This blog was started on LiveJournal shortly after I graduated high school in 2009. It has survived this long because I was very persistent about porting all my posts to Blogger, and then to my own static website. Of course, I have limits. Most of my <em>terrible</em> old posts were removed long ago, because they were so bad they didn't contribute anything. One post was a rant about my high school internship at Microsoft. I took it down because it was bad, but more importantly I took it down because I wrote it before graduating college, while I was still <strong>completely delusional</strong>.</p><p>Let me explain.</p><p>I grew up 20 minutes from Microsoft. I had absolutely no idea what an absurdly warped childhood I had until I graduated college and met people who hadn't grown up in a tech bubble. I never questioned how my middle school always somehow had the latest copy of Windows and maintained <strong>six different computer labs</strong> (one in each classroom hub, plus the library, plus a dedicated lab). I didn't realize how unusual it was for my high school to offer an &ldquo;intro to game dev course&rdquo; <em>in 2008</em>, or how ridiculous it was that my AP Computer Science professor had worked on the first version of DirectX at Microsoft. I never thought it was weird that we had Microsoft Connector buses driving around town, creating <em>an entire secondary bus system</em> for the sole purpose of moving around Microsoft employees.</p><p>I <em>definitely</em> did not realize how utterly insane it was that, in July 2006, students from my high school (and a few other high schools around the area) were invited to a week long event where we would get to experiment with and &ldquo;bug test&rdquo; a beta version of Windows Vista, a full six months before it was released. At 8:00AM every morning, our parents dropped us off at Microsoft Building 40, and we were led into a room filled with rows of desks with computers on them. There were maybe 50 of us, and we were given guest accounts and full internet access while Microsoft employees gave presentations about various new features they had introduced for Vista.</p><p>I still remember some of those presentations. One that really stuck with me at the time was Microsoft jumping on the &ldquo;192kHz sampling rate support&rdquo; bandwagon, which <a href=https://people.xiph.org/~xiphmont/demo/neil-young.html>makes absolutely no sense</a> outside of music production, and in retrospect just seems incredibly dumb. Another presentation had us build wifi mesh networks between the computers, which was touted as a way to share files and communicate with friends in places with little to no internet connectivity. I remember this one both because I thought it was very cool, and because someone managed to bluescreen Windows while attempting to set it up, so they actually had an SDE come in and take a look.</p><p>In their attempts to make this a &ldquo;camp&rdquo; experience, they gave us all a project on the final day: create our own presentation (using the new Microsoft™ Office™ PowerPoint™ 2007, of course), about some new feature we wanted on Windows or some improvement that wasn't there yet. I don't remember what our presentation was, but I do know we were all terrible. Afterwards we were all invited to the &ldquo;Windows Vista Consumer Support Assisted Beta&rdquo;, a predecessor to the Windows Insider program.</p><p>This &ldquo;Camp Vista&rdquo; thing was a strange, one-time event, but the Hunt The Wumpus competition <a href=https://www.lwsd.org/programs-and-services/communications/news/news-details/~board/high-schools/post/lwsd-teams-compete-in-microsofts-hunt-the-wumpus-game-design-competition>is still going</a>. If you're lucky enough to be attending school in the Lake Washington School District, you can team up with several other students and get <em>tutoring from a Microsoft employee</em> over the course of several months while you build a very basic video game and compete for Microsoft sponsored prizes. I fondly remember our attempts at building a game using <a href=https://en.wikipedia.org/wiki/Microsoft_XNA>XNA</a> back when it was brand new (it's now dead), and making a bad <a href=https://en.wikipedia.org/wiki/Descent_(video_game)>Descent</a> clone. We tried to use SVN, but weren't allowed to install it on school computers, so we resorted to an FTP folder and e-mailing zip files.</p><p>Here we have the crux of the problem with my initial impressions of my high school internship - <em>it's not a normal thing!</em> Students worldwide compete for a chance to get college internships at Microsoft, but the high school interns are just random CS students from the Lake Washington School District. When my team learned I knew quite a bit of programming already, they had to <em>come up with something else for me to do</em> because they had assumed I barely knew how to code. It was just another outreach program for nearby high schools, only available to <strong><a href="https://www.lwsd.org/programs-and-services/communications/news/news-details/~board/2019-20-announcements/post/lake-washington-school-district-now-second-largest-district-in-washington-state#:~:text=Lake%20Washington%20School%20District%20is,31%2C100%20students%20in%2056%20schools">31000 kids</a></strong> on the <em>entire planet</em>.</p><p>So in the midst of me having an experience that <em>almost no other high school student gets to have</em>, I am complaining about things like &ldquo;wow, we have too many meetings&rdquo; and &ldquo;wow, this software is bad&rdquo;. Yes, we know Microsoft is a dysfunctional catastrophe, but focusing on issues that are omnipresent in large corporations only serves to detract from the actual crazy parts of the internship, like how the program we were working on, if compiled with no optimizations, <strong>took 20 minutes to start</strong>. Or the meeting where the entire team spent 15 in-person minutes sitting around an actual table deciding that one of our function names was too long and debated over what to rename it before deciding not to change it. Or that one time the department head (my boss's boss's boss) took me, an intern, to a meeting <em>with his boss</em>, who I think directly reported to a vice president. It got better, though, because one afternoon, there was a 3-hour period of time where my boss, his boss, <em>and the department head</em> were all gone, so I, a 19-year-old high school student, was technically supposed to take my questions about how to use C# <code>PInvoke</code> <em>to the department head's boss</em>.</p><p>I was really careful not to break anything for 3 hours.</p><p>Looking back at my teenage years has made me realize how easy it is for people to simply miss how some aspect of their upbringing was deeply unusual. For some, it may be a silent hindrance, but for others, it might be a quiet boon, softly sending opportunities their way that almost no one else has access to. How many opportunities did I let slip by, unaware of how unique they were?</p></div><hr><time itemprop=datePublished pubdate=pubdate datetime=2022-06-13T22:39:00+00:00><i class="fa fa-clock-o fa-fw"></i>&nbsp;Published on <a href=https://erikmcclure.com/blog/camp-vista/>June 13, 2022 at 10:39pm</a></time><aside><a href=/blog/camp-vista/#comments><i class="fa fa-comments-o fa-fw"></i>&nbsp;0 comments</a></aside><aside><i class="fa fa-share-square-o fa-fw"></i>&nbsp;share:<ul><li><a href="javascript:window.open('https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ferikmcclure.com%2fblog%2fcamp-vista%2f','popup','width=600,height=400');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" d="M16.75 9H13.5V7a1 1 0 011-1h2V3H14a4 4 0 00-4 4V9H8v3h2v9h3.5V12H16z"/></svg></a><li><a href="javascript:window.open('https://twitter.com/intent/tweet?text=Camp%20Vista%20-%20Growing%20Up%20Next%20To%20Microsoft&url=https%3a%2f%2ferikmcclure.com%2fblog%2fcamp-vista%2f','popup','width=600,height=256');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" opacity="0" d="M0 0h24v24H0z"/><path class="st0" d="M23.643 4.937c-.835.37-1.732.62-2.675.733.962-.576 1.7-1.49 2.048-2.578-.9.534-1.897.922-2.958 1.13-.85-.904-2.06-1.47-3.4-1.47-2.572.0-4.658 2.086-4.658 4.66.0.364.042.718.12 1.06-3.873-.195-7.304-2.05-9.602-4.868-.4.69-.63 1.49-.63 2.342.0 1.616.823 3.043 2.072 3.878-.764-.025-1.482-.234-2.11-.583v.06c0 2.257 1.605 4.14 3.737 4.568-.392.106-.803.162-1.227.162-.3.0-.593-.028-.877-.082.593 1.85 2.313 3.198 4.352 3.234-1.595 1.25-3.604 1.995-5.786 1.995-.376.0-.747-.022-1.112-.065 2.062 1.323 4.51 2.093 7.14 2.093 8.57.0 13.255-7.098 13.255-13.254.0-.2-.005-.402-.014-.602.91-.658 1.7-1.477 2.323-2.41z"/></svg></a></li><li><a href="javascript:window.open('https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ferikmcclure.com%2fblog%2fcamp-vista%2f','popup','width=700,height=380');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><rect class="st0" height="11" width="4" x="3" y="9"/><circle class="st0" cx="5" cy="5" r="2"/><path class="st0" d="M16.5 8.25A4.47251 4.47251.0 0013 9.95343V9H9V20h4V13a2 2 0 014 0v7h4V12.75a4.5 4.5.0 00-4.5-4.5z"/></svg></a></li><li><a href="javascript:window.open('https://plus.google.com/share?app=110&url=https%3a%2f%2ferikmcclure.com%2fblog%2fcamp-vista%2f','popup','width=400,height=380');"><svg xmlns="http://www.w3.org/2000/svg" viewBox="4 2 52.6934 50.6934" class="icon-img" height="24"><style>.st0{fill:#666}</style><g><path class="st0" d="M19.6671 25.7867c-.0075 1.7935.0 3.5869.0076 5.3803 3.0067.098 6.0208.0527 9.0275.098-1.3262 6.6689-10.3989 8.8315-15.199 4.4761C8.5674 31.9206 8.801 23.5412 13.9327 19.992c3.5869-2.8635 8.6884-2.1552 12.2752.324 1.4092-1.3036 2.7278-2.6977 4.0013-4.1445-2.984-2.3812-6.6462-4.0767-10.5421-3.8958-8.1307-.2713-15.6059 6.8497-15.7415 14.9805-.52 6.6462 3.8506 13.1644 10.0222 15.5155 6.1489 2.3661 14.031.7535 17.957-4.77 2.5922-3.4889 3.1498-7.98 2.8484-12.1999C29.7194 25.7641 24.6933 25.7716 19.6671 25.7867z"/><path class="st0" d="M49.0704 25.7641c-.0151-1.4996-.0226-3.0067-.0301-4.5062-1.4996.0-2.9916.0-4.4836.0-.0151 1.4996-.0301 2.9991-.0377 4.5062-1.5071.0075-3.0067.0151-4.5062.0302.0 1.4995.0 2.9915.0 4.4836 1.4995.0151 3.0066.0302 4.5062.0452.0151 1.4996.0151 2.9991.0302 4.4987 1.4996.0 2.9916.0 4.4911.0.0075-1.4996.015-2.9991.0301-4.5062 1.5071-.0151 3.0067-.0226 4.5062-.0377.0-1.4921.0-2.9916.0-4.4836C52.0771 25.7792 50.57 25.7792 49.0704 25.7641z"/></g></svg></a></li></ul></aside></article><article><h4><a href=/blog/blockchain-new-javascript/>Blockchain Is The New JavaScript</a></h4><hr><div class=padding><p>Over 25 years ago, Brenden Eich created JavaScript, named after Java simply because it was popular. It's prototypical nature and dynamic typing made it unsuitable for anything other than slow interpreters, forcing Google to <em>invent a way to <a href=https://en.wikipedia.org/wiki/V8_(JavaScript_engine)>JIT the language</a></em> just to make it fast. We even built a package manager for JavaScript which managed to create such an absurd dependency hell that <a href=https://qz.com/646467/how-one-programmer-broke-the-internet-by-deleting-a-tiny-piece-of-code/>one guy's left-pad function managed to break web development</a> for a day.</p><p>Now the entire world economy runs on JavaScript.</p><p>This is the kind of dumb future that we live in, and it is the kind of dumb future we can look forward to with blockchain. It is why people who insist that blockchain will never work because of various technological reasons are ignoring the simple fact that humanity is incredibly good at standardizing on the worst possible things, then building our entire future on top of them. In fact, there is a disturbing number of direct parallels between the rise of JavaScript and the rise of blockchain technologies, with a few key differences.</p><p>JavaScript was originally <a href=https://brendaneich.com/2008/04/popularity/>going to be Scheme</a>, a lisp dialect. Sadly, the management demanded that it look more like Java, so Brenden hid Scheme inside a vaguely Java-esque syntax, which became Mocha, which became LiveScript, which then became JavaScript. This has led to many suffering web developers agonizing over the fact that &ldquo;We could have had Lisp!". Even worse, <a href=https://eager.io/blog/the-languages-which-almost-were-css/>CSS originated in DSSSL</a>, which was another dialect of Scheme for constructing style sheets, but it was deemed too complicated (too many parenthesis!), so a much simpler version was created, called CSS. Modern CSS, of course, has simply reinvented everything DSSSL had, except worse.</p><p>This is what drives the entire internet, and in turn, Amazon's trillion dollar empire.</p><p>In 2009, Satoshi Nakamoto unleashed Bitcoin upon an unsuspecting world. Most people ignored it, for good reason - it was completely impractical for any sort of global transaction system, capable of processing a whopping <a href=https://en.wikipedia.org/wiki/Bitcoin_scalability_problem>7 transaction per second</a>. Then the first bubble happened and Bitcoin skyrocketed to $1000 USD in late 2013. It then promptly crashed to $300 in 2014, after which most people thought it had simply been a passing fad, and ignored it for the next 3 years, until the second bubble of 2017.</p><p>But not everyone. After his favorite World of Warcraft spell got nerfed by Blizzard, <del>some maniac</del> <a href=https://en.wikipedia.org/wiki/Vitalik_Buterin>Vitalik Buterin</a> argued that the Bitcoin network should support programmable smart contracts, at the peak of the 2013 bubble. Here, we almost had a repeat of JavaScript, nearly bolting on smart contracts to a blockchain algorithm that was never designed for it. However, history thankfully granted us a reprieve, because the Bitcoin developers told Vitalik to take a hike. So, he invented Ethereum, which is like Bitcoin except slightly less stupid. Unfortunately, it still ran on Proof-of-Work, which means <a href=https://abcnews.go.com/US/wireStory/bitcoin-mining-power-plant-raises-ire-environmentalists-80618790>burning coal to solve sudokus</a>.</p><p>At this point, you may be expecting me to draw a parallel from Google's V8 JavaScript engine to <a href=https://ethereum.org/en/eth2/beacon-chain/>Proof-of-Stake</a>, but that actually isn't correct. Proof-of-Stake doesn't make the network faster, it just lets the network run without wasting astronomical amounts of energy. Proof-of-Stake is more analogous to the introduction of AJAX in 1999, the foundational JavaScript extension that allowed for asynchronous websites, and in turn, the entire modern web. Proof-of-Stake is a change that finally makes Ethereum <em>usable</em> for large scale smart contracts without burning ludicrous amounts of electricity to run the network. This, however, isn't enough, because Ethereum's network is still <em>painfully slow</em>. Granted, at <a href=https://etherchain.org/>14 transactions per second</a>, it's at least twice as fast as Bitcoin, but that doesn't really count for much when you need to be several orders of magnitude faster.</p><p>So, naturally, just like we did with JavaScript, a bunch of extremely smart people are inventing ways to make Ethereum's horribly slow network go really fast, either by creating <a href=https://ethereum.org/en/developers/docs/scaling/layer-2-rollups/>Layer 2 Rollups</a>, or via sharding through the <a href=https://ethereum.org/en/eth2/shard-chains/>proposed Shard Chains</a>. Individually, these optimizations are expected to yield 2000-3000 transactions per second, and if combined, the optimistic estimate is that it will allow <a href=https://twitter.com/VitalikButerin/status/1277961594958471168>hundreds of thousands of transactions per second</a>. We'll have to wait until we see the true results of the speedups, but even the pessimistic estimations expect a 100x increase in transaction speed with existing Layer 2 rollup solutions, which is a pretty big deal.</p><p>Of course, if you give an inch, they'll take a mile, and when Web Developers discovered that we could make JavaScript go fast, they started putting entire software solutions on the web. We got Web Apps. We got Electron. Now I've got JavaScript running <a href=https://code.visualstudio.com/>in my goddamn IDE</a> and there's no end in sight. We've forgotten how to make native apps (and the lack of good UI solutions for anything other than JavaScript hasn't helped, either), so now the Web isn't just inside your Web Browser, it's in all your programs too. We've created a monster, and there's no getting it back in the box.</p><p>This, I think, is something we should keep in mind when criticizing &ldquo;unnecessary&rdquo; blockchain solutions. Opponents of blockchain correctly point out that there are, in fact, very few things that actually need to be decentralized. Oftentimes, you can achieve decentralization through federation, or a DHT, or some other option instead, without needing an entire decentralized permanent public ledger. In many cases, having a permanent write-only public ledger is objectively worse than existing solutions.</p><p>These criticisms are all 100% true and also <em>don't matter</em>. If software actually needed to work well in order for people to use it, nobody would use anything Oracle made. Our future is filled with blockchains that we have spent obscene amounts of time and effort to make fast so we can create centralized decentralized solutions, private public ledgers, and dumb smart contracts. There <strong>are</strong> good ideas buried underneath this mess, but if we spend our time railing against blockchain instead of implementing them, all we'll get is more <code>left-pad</code>. We only have one chance to make the future suck less, even if we're just <a href=https://soatok.blog/2021/10/19/against-web3-and-faux-decentralization/>proposing less awful blockchain designs</a>.</p><p>This is why I have begun learning the basics of blockchain - not because any of this makes sense, or is even a good idea. I simply recognize that the future is coming, and the future is dumb.</p></div><hr><time itemprop=datePublished pubdate=pubdate datetime=2021-10-18T01:06:00+00:00><i class="fa fa-clock-o fa-fw"></i>&nbsp;Published on <a href=https://erikmcclure.com/blog/blockchain-new-javascript/>October 18, 2021 at 1:06am</a></time><aside><a href=/blog/blockchain-new-javascript/#comments><i class="fa fa-comments-o fa-fw"></i>&nbsp;0 comments</a></aside><aside><i class="fa fa-share-square-o fa-fw"></i>&nbsp;share:<ul><li><a href="javascript:window.open('https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ferikmcclure.com%2fblog%2fblockchain-new-javascript%2f','popup','width=600,height=400');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" d="M16.75 9H13.5V7a1 1 0 011-1h2V3H14a4 4 0 00-4 4V9H8v3h2v9h3.5V12H16z"/></svg></a><li><a href="javascript:window.open('https://twitter.com/intent/tweet?text=Blockchain%20Is%20The%20New%20JavaScript&url=https%3a%2f%2ferikmcclure.com%2fblog%2fblockchain-new-javascript%2f','popup','width=600,height=256');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" opacity="0" d="M0 0h24v24H0z"/><path class="st0" d="M23.643 4.937c-.835.37-1.732.62-2.675.733.962-.576 1.7-1.49 2.048-2.578-.9.534-1.897.922-2.958 1.13-.85-.904-2.06-1.47-3.4-1.47-2.572.0-4.658 2.086-4.658 4.66.0.364.042.718.12 1.06-3.873-.195-7.304-2.05-9.602-4.868-.4.69-.63 1.49-.63 2.342.0 1.616.823 3.043 2.072 3.878-.764-.025-1.482-.234-2.11-.583v.06c0 2.257 1.605 4.14 3.737 4.568-.392.106-.803.162-1.227.162-.3.0-.593-.028-.877-.082.593 1.85 2.313 3.198 4.352 3.234-1.595 1.25-3.604 1.995-5.786 1.995-.376.0-.747-.022-1.112-.065 2.062 1.323 4.51 2.093 7.14 2.093 8.57.0 13.255-7.098 13.255-13.254.0-.2-.005-.402-.014-.602.91-.658 1.7-1.477 2.323-2.41z"/></svg></a></li><li><a href="javascript:window.open('https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ferikmcclure.com%2fblog%2fblockchain-new-javascript%2f','popup','width=700,height=380');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><rect class="st0" height="11" width="4" x="3" y="9"/><circle class="st0" cx="5" cy="5" r="2"/><path class="st0" d="M16.5 8.25A4.47251 4.47251.0 0013 9.95343V9H9V20h4V13a2 2 0 014 0v7h4V12.75a4.5 4.5.0 00-4.5-4.5z"/></svg></a></li><li><a href="javascript:window.open('https://plus.google.com/share?app=110&url=https%3a%2f%2ferikmcclure.com%2fblog%2fblockchain-new-javascript%2f','popup','width=400,height=380');"><svg xmlns="http://www.w3.org/2000/svg" viewBox="4 2 52.6934 50.6934" class="icon-img" height="24"><style>.st0{fill:#666}</style><g><path class="st0" d="M19.6671 25.7867c-.0075 1.7935.0 3.5869.0076 5.3803 3.0067.098 6.0208.0527 9.0275.098-1.3262 6.6689-10.3989 8.8315-15.199 4.4761C8.5674 31.9206 8.801 23.5412 13.9327 19.992c3.5869-2.8635 8.6884-2.1552 12.2752.324 1.4092-1.3036 2.7278-2.6977 4.0013-4.1445-2.984-2.3812-6.6462-4.0767-10.5421-3.8958-8.1307-.2713-15.6059 6.8497-15.7415 14.9805-.52 6.6462 3.8506 13.1644 10.0222 15.5155 6.1489 2.3661 14.031.7535 17.957-4.77 2.5922-3.4889 3.1498-7.98 2.8484-12.1999C29.7194 25.7641 24.6933 25.7716 19.6671 25.7867z"/><path class="st0" d="M49.0704 25.7641c-.0151-1.4996-.0226-3.0067-.0301-4.5062-1.4996.0-2.9916.0-4.4836.0-.0151 1.4996-.0301 2.9991-.0377 4.5062-1.5071.0075-3.0067.0151-4.5062.0302.0 1.4995.0 2.9915.0 4.4836 1.4995.0151 3.0066.0302 4.5062.0452.0151 1.4996.0151 2.9991.0302 4.4987 1.4996.0 2.9916.0 4.4911.0.0075-1.4996.015-2.9991.0301-4.5062 1.5071-.0151 3.0067-.0226 4.5062-.0377.0-1.4921.0-2.9916.0-4.4836C52.0771 25.7792 50.57 25.7792 49.0704 25.7641z"/></g></svg></a></li></ul></aside></article><article><h4><a href=/blog/cpp-constructors-memory-and-lifetimes/>C++ Constructors, Memory, and Lifetimes</a></h4><hr><div class=padding><div class=imgwrap style=max-width:400px><a href=/img/cpp_init_forest.gif target=_blank><img src=/img/cpp_init_forest.gif alt="C++ Initialization Hell" width=100%></a></div><p>What exactly happens when you write <code><code>Foo* foo = new Foo();</code></code>? A lot is packed into this one statement, so lets try to break it down. First, this example is allocating new memory on the heap, but in order to understand everything that's going on, we're going to have to explain what it means to declare a variable <em>on the stack</em>. If you already have a good understanding of how the stack works, and how functions do cleanup before returning, feel free to skip to the <a href=#new-statements>new statement</a>.</p><h3 id=stack-lifetimes>Stack Lifetimes</h3><p>Describing the stack is very often glossed over in many other imperative languages, despite the fact that those languages still have one (functional languages are an entirely different level of weird). Let's start with something very simple:<pre class=language-cpp><code>int foobar(int b)
{
  int a;
  a = b;
  return a;
}
</code></pre>Here, we are declaring a function <code>foobar</code> that takes an <code>int</code> and returns an <code>int</code>. The first line of the function declares a variable <code>a</code> of type <code>int</code>. This is all well and good, but <em>where is the integer?</em>. On most modern platforms, <code>int</code> resolves to a 32-bit integer that takes up 4 bytes of space. We haven't allocated any memory yet, because no <code>new</code> statement happened and no <code>malloc()</code> was called. Where is the integer?</p><p>The answer is that the integer was allocated on the <em>stack</em>. If you aren't familiar with the <a href=https://en.wikipedia.org/wiki/Stack_(abstract_data_type)>computer science data structure</a> of the same name, your program is given a chunk of memory by the operating system that is organized into a stack structure, hence the name. It's like a stack of plates - you can push items on top of the stack, or you can remove items from the top of the stack, but you can't remove things from the middle of the stack or all the plates will come crashing down. So if we push something on top of the stack, we're stuck with it until we get rid of everything on top of it.</p><p>When we called our function, the parameter <code>int b</code> was pushed on to the stack. Parameters take up memory, so on to the stack they go. Hence, before we ever reach the statement <code>int a</code>, 4 bytes of memory were already pushed onto our stack. Here's what our stack looks like at the beginning of the function if we call it with the number <code>90</code> (assuming little-endian):</p><div class=imgwrap style=max-width:450px><a href=/img/stack1.svg target=_blank><img src=/img/stack1.svg alt="Stack for b" width=100%></a></div><p><code>int a</code> tells the compiler to push another 4 bytes of memory on to the stack, but it has no initial value, so the contents are undefined:</p><div class=imgwrap style=max-width:450px><a href=/img/stack2.svg target=_blank><img src=/img/stack2.svg alt="Stack for a and b" width=100%></a></div><p><code>a = b</code> assigns b to a, so now our stack looks like this:</p><div class=imgwrap style=max-width:450px><a href=/img/stack3.svg target=_blank><img src=/img/stack3.svg alt="Stack for initialized a and b" width=100%></a></div><p>Finally, <code>return a</code> tells the compiler to evaluate the return expression (which in our case is just <code>a</code> so there's nothing to evaluate), then copy the result into a chunk of memory we reserved ahead of time for the return value. Some programmers may assume the function returns <em>immediately</em> once the <code>return</code> statement is executed - after all, that's what <code>return</code> means, right? However, the reality is that the function still has to clean things up before it can actually return. Specifically, we need to return our stack to the state it was before the function was called by removing everything we pushed on top of it <strong>in reverse order</strong>. So, after copying our return value <code>a</code>, our function pops the top of the stack off, which is the last thing we pushed. In our case, that's <code>int a</code>, so we pop it off the stack. Our stack now looks like this:</p><div class=imgwrap style=max-width:450px><a href=/img/stack1.svg target=_blank><img src=/img/stack1.svg alt="Stack without a" width=100%></a></div><p>The moment from which <code>int a</code> was pushed onto the stack to the moment it was popped off the stack is called the <strong>lifetime</strong> of <code>int a</code>. In this case, <code>int a</code> has a lifetime of the entire function. After the function returns, our caller has to pop off <code>int b</code>, the parameter we called the function with. Now our stack is empty, and the <strong>lifetime</strong> of <code>int b</code> is longer than the <strong>lifetime</strong> of <code>int a</code>, because it was pushed first (before the function was called) and popped afterwards (after the function returned). C++ builds it's entire concept of constructors and destructors on this concept of lifetimes, and they can get very complicated, but for now, we'll focus only on stack lifetimes.</p><p>Let's take a look at a more complex example:<pre class=language-cpp><code>int foobar(int b)
{
  int a;
  
  {
    int x;
    x = 3;
    
    {
      int z;
      int max;
      
      max = 999;
      z = x + b;
      
      if(z &gt; max)
      {
        return z - max;
      }
      
      x = x + z;
    }
    
    // a = z; // COMPILER ERROR!
    
    {
      int ten = 10;
      a = x + ten;
    }
  } 
  
  return a;
}
</code></pre>Let's look at the lifetimes of all our parameters and variables in this function. First, before calling the function, we push <code>int b</code> on to the stack with the value of whatever we're calling the function with - say, <code>900</code>. Then, we call the function, which immediately pushes <code>int a</code> on to the stack. Then, we <em>enter a new block</em> using the character <code>{</code>, which does not consume any memory, but instead acts as a marker for the compiler - we'll see what it's used for later. Then, we push <code>int x</code> on to the stack. We now have 3 integers on the stack. We set <code>int x</code> to <code>3</code>, but <code>int a</code> is still undefined. Then, we <em>enter another new block</em>. Nothing interesting has happened yet. We then push both <code>int z</code> and <code>int max</code> on to the stack. Then we assign <code>999</code> to <code>int max</code> and assign <code>int z</code> the value <code>x + b</code> - if we passed in <code>900</code>, this means <code>z</code> is now equal to <code>903</code>, which is less than the value of <code>int max</code> (<code>999</code>), so we skip the if statement for now. Then we assign <code>x</code> to <code>x + z</code>, which will be <code>906</code>.</p><p>Now things get interesting. Our topmost block <strong>ends</strong> with a <code>}</code> character. This tells the compiler to <em>pop all variables declared inside that block</em>. We pushed <code>int z</code> on to the stack inside this block, so it's gone now. We cannot refer to <code>int z</code> anymore, and doing so will be a compiler error. <code>int z</code> is said to have <em>gone out of scope</em>. However, we also pushed <code>int max</code> on to the stack, and we pushed it after <code>int z</code>. This means that the compiler will <strong>first pop <code>int max</code> off the stack</strong>, and only afterwards will it then pop <code>int z</code> off the stack. The order in which this happens will be critical for understanding how lifetimes work with constructors and destructors, so keep it in mind.</p><p>Then, we enter another new scope. This new scope is still inside the first scope we created that contains <code>int x</code>, so we can still access <code>x</code>. We define <code>int ten</code> and initialize it with <code>10</code>. Then we set <code>int a</code> equal to <code>x + ten</code>, which will be <code>916</code>. Then, our scope ends, and <code>int ten</code> goes out of scope, being popped off the stack. Immediately afterwards, we reach the end of our first scope, and <code>int x</code> is popped off the stack.</p><p>Finally, we reach <code>return a</code>, which copies <code>a</code> to our return value memory segment, pops <code>int a</code>, and returns to our caller, who then pops <code>int b</code>. That's what happens when we pass in <code>900</code>, but what happens if we pass in <code>9000</code>?</p><p>Everything is the same until we reach the <code>if</code> statement, whose condition is now satisfied, which results in the function terminating early and returning <code>z - max</code>. What happens to the stack?</p><p>When we reach <code>return z - max</code>, the compiler evaluates the statement and copies the result (<code>8004</code>) out. Then it starts popping everything off the stack (once again, in the reverse order that things were pushed). The last thing we pushed on to the stack was <code>int max</code>, so it gets popped first. Then <code>int z</code> is popped. Then <code>int x</code> is popped. Then <code>int a</code> is popped, the function returns, and finally <code>int b</code> is popped by the caller. This behavior is critical to how C++ uses lifetimes to implement things like smart pointers and automatic memory management. Rust actually uses a similar concept, but it uses it for a lot more than C++ does.</p><h3 id=new-statements><code>new</code> Statements</h3><p>Okay, now we know how lifetimes work and where variables live when they aren't allocated, but what happens when you <em>do</em> allocate memory? What's going on with the <code>new</code> statement? To look at this, let's use a simplified example:<pre class=language-cpp><code>int* foo = new int();
</code></pre>Here we have allocated a pointer to an integer on the stack (which will be 8 bytes if you're on a 64-bit system), and assigned the result of <code>new int()</code> to it. What happens when we call <code>new int()</code>? In C++, the <code>new</code> operator is an extension of <code>malloc()</code> from C. This means it allocates memory from the <em>heap</em>. When you allocate memory on the heap, it never goes out of scope. This is what most programmers are familiar with in other languages, except that most other languages handle figuring out when to deallocate it and C++ forces you to delete it yourself. Memory allocated on the heap is just there, floating around, forever, or until you deallocate it. So this function has a memory leak:<pre class=language-cpp><code>int bar(int b)
{
  int* a = new int();
  *a = b;
  return *a;
}
</code></pre>This is the same as our <a href=#stack-lifetimes>first example</a>, except now we allocate <code>a</code> on the heap instead of the stack. So, it never goes out of scope. It's just there, sitting in memory, forever, until the process is terminated. The <code>new</code> operator looks at the type we passed it (which is <code>int</code> in this case) and calls <code>malloc</code> for us with the appropriate number of bytes. Because <code>int</code> has no constructors or destructors, it's actually equivelent to this:<pre class=language-cpp><code>int bar(int b)
{
  int* a = (int*)malloc(sizeof(int));
  *a = b;
  return *a;
}
</code></pre>Now, people who are familiar with C will recognize that any call to <code>malloc</code> should come with a call to <code>free</code>, so how do we do that in C++? We use <code>delete</code>:<pre class=language-cpp><code>int bar(int b)
{
  int* a = new int();
  *a = b;
  int r = *a;
  delete a;
  return r;
}
</code></pre><strong>IMPORTANT:</strong> Never mix <code>new</code> and <code>free</code> or <code>malloc</code> and <code>delete</code>. The <code>new</code>/<code>delete</code> operators can use a different allocator than <code>malloc</code>/<code>free</code>, so things will violently explode if you treat them as interchangeable. Always <code>free</code> something from <code>malloc</code> and always <code>delete</code> something created with <code>new</code>.</p><p>Now we aren't leaking memory, but we also can't do <code>return *a</code> anymore, because it's impossible for us to do the necessary cleanup. If we were allocating on the stack, C++ would clean up our variable for us after the <code>return</code> statement, but we can't put anything after the return statement, so there's no way to tell C++ to copy the value of <code>*a</code> and <em>then</em> manually delete <code>a</code> without introducing a new variable <code>r</code>. Of course, if we could run arbitrary code when our variable went out of scope, we could solve this problem! This sounds like a job for constructors and destructors!</p><h3 id=constructors-and-delete>Constructors and <code>delete</code></h3><p>Okay, let's put everything together and return to our original statement in a more complete example:<pre class=language-cpp><code>struct Foo
{
  // Constructor for Foo
  Foo(int b)
  {
    a = b;
  }
  // Empty Destructor for Foo
  ~Foo() {}
  
  int a;
};

int bar(int b)
{
  // Create
  Foo* foo = new Foo(b);
  int a = foo-&gt;a;
  // Destroy
  delete foo;
  return a; // Still can&#39;t return foo-&gt;a
}
</code></pre>In this code, we still haven't solved the return problem, but we are now using constructors and destructors, so let's walk through what happens. First, <code>new</code> allocates memory on the heap for your type. <code>Foo</code> contains a 32-bit integer, so that's 4 bytes. Then, <em>after</em> the memory is allocated, <code>new</code> automatically calls the <em>constructor</em> that matches whatever parameters you pass to the type. Your constructor doesn't need to allocate any memory to contain your type, since <code>new</code> already did this for you. Then, this pointer is assigned to <code>foo</code>. Then we delete <code>foo</code>, which <strong>calls the destructor first</strong> (which does nothing), and <em>then</em> deallocates the memory. If you don't pass any parameters when calling <code>new Type()</code>, or you are creating an array, C++ will simply call the default constructor (a constructor that takes no parameters). This is all equivelent to:<pre class=language-cpp><code>int bar(int b)
{
  // Create
  Foo* foo = (Foo*)malloc(sizeof(Foo));
  new (foo) Foo(b); // Special new syntax that ONLY calls the constructor function (this is how you manually call constructors in C++)
  int a = foo-&gt;a; 
  // Destroy
  foo-&gt;~Foo(); // We can, however, call the destructor function directly
  free(foo);
  
  return a; // Still can&#39;t return foo-&gt;a
}
</code></pre>This uses a special new syntax that doesn't allocate anything and simply lets us call the constructor function directly on our already allocated memory. This is what the <code>new</code> operator is doing for you under the hood. We then call the destructor manually (which you <em>can</em> do) and free our memory. Of course, this is all still useless, because we can't return the integer we allocated on the heap!</p><h3 id=destructors-and-lifetimes>Destructors and lifetimes</h3><p>Now, the magical part of C++ is that constructors and destructors are run <em>when things are pushed or popped from the stack</em> <sup><a href=#f1>[1]</a></sup>. The fact that constructors and destructors respect variable lifetimes allows us to solve our problem of cleaning up a heap allocation upon returning from a function. Let's see how that works:<pre class=language-cpp><code>struct Foo
{
  // Default constructor for Foo
  Foo()
  {
    a = new int();
  }
  // Destructor frees memory we allocated using delete
  ~Foo()
  {
    delete a;
  }
  
  int* a;
};

int bar(int b)
{
  Foo foo;
  *foo.a = b;
  return *foo.a; // Doesn&#39;t leak memory!
}
</code></pre>How does this avoid leaking memory? Let's walk through what happens: First, we declare <code>Foo foo</code> on the stack, which pushes 4 bytes on to the stack, and then C++ calls our default constructor. Inside our default constructor, we use <code>new</code> to allocate a new integer and store it in <code>int* a</code>. Returning to our function, we then set our integer pointer <code>foo.a</code> to <code>b</code>. Then, we return the value stored in <code>foo.a</code> from the function<sup><a href=#f2>[2]</a></sup>. This copies the value out of <code>foo.a</code> first by dereferencing the pointer, and <em>then</em> C++ calls our destructor <code>~Foo</code> before <code>Foo foo</code> is popped off the stack. This destructor deletes <code>int* a</code>, ensuring we don't leak any memory. Then we pop off <code>int b</code> from the stack and the function returns. If we could somehow do this without constructors or destructors, it would look like this:<pre class=language-cpp><code>int bar(int b)
{
  Foo foo;
  foo.a = new int();
  *foo.a = b;
  int retval = *foo.b;
  delete a;
  return retval;
}
</code></pre>The ability to run a destructor when something goes out of scope is an incredibly important part of writing good C++ code, becuase when a function returns, <em>all</em> your variables go out of scope when the stack is popped. Thus, all cleanup that is done during destructors is gauranteed to run no matter when you return from a function. Destructors are gauranteed to run <strong>even when you throw an exception!</strong> This means that if you throw an exception that gets caught farther up in the program, you won't leak memory, because C++ ensures that everything on the stack is correctly destroyed when processing exception handling, so all destructors are run in the same order they normally are.</p><p>This is the core idea behind smart pointers - if a pointer is stored inside an object, and that object deletes the pointer in the destructor, then you will never leak the pointer because C++ ensures that the destructor will eventually get called when the object goes out of scope. Now, if implemented naively there is no way to pass the pointer into different functions, so the utility is limited, but C++11 introduced <strong>move semantics</strong> to help solve this issue. We'll talk about those later. For now, let's talk about different kinds of lifetimes and what they mean for when constructors and destructors are called.</p><h3 id=static-lifetimes>Static Lifetimes</h3><p>Because any struct or class in C++ can have constructors or destructors, and you can put structs or classes anywhere in a C++ program, this means that there are rules for how to safely invoke constructors and destructors in all possible cases. These different possible lifetimes have different names. Global variables, or static variables inside classes, have what's called &ldquo;static lifetime&rdquo;, which means their lifetime begins when the program starts and ends once the program exits. The exact order these constructors are called, however, is a bit tricky. Let's look at an example:<pre class=language-cpp><code>struct Foo
{
  // Default constructor for Foo
  Foo()
  {
    a = new int();
  }
  // Destructor frees memory we allocated using delete
  ~Foo()
  {
    delete a;
  }
  
  int* a;
  static Foo instance;
};

static Foo GlobalFoo;

int main()
{
  *GlobalFoo.a = 3;
  *Foo::instance.a = *GlobalFoo.a;
  return *Foo::instance.a;
}
</code></pre>When is <code>instance</code> constructed? When is <code>GlobalFoo</code> constructed? Can we safely assign to <code>GlobalFoo.a</code> immediately? The answer is that all static lifetimes are constructed <strong>before your program even starts</strong>, or more specifically, before <code>main()</code> is called. Thus, by the time your program has reached your entry point (<code>main()</code>), C++ gaurantees that all static lifetime objects have already been constructed. But what <em>order</em> are they constructed in? This gets complicated. Basically, static variables are constructed in the order they are declared in a single <code>.cpp</code> file. However, the order these <code>.cpp</code> files are constructed in is undefined. So, you can have static variables that rely on each other inside a single <code>.cpp</code> file, but never between different files.</p><p>Likewise, all static lifetime objects get deconstructed <em>after</em> your <code>main()</code> function returns, and once again, this order is random, although it <em>should</em> be in the reverse order they were constructed in. Technically this should be respected even if an exception occurs, but because the compiler can assume the process will terminate immediately after an unhandled exception occurs, this is unreliable.</p><p>Static lifetimes still apply for shared libraries, and are constructed the moment the library is loaded into memory - that's <code>LoadLibrary</code> on Windows and <code>dlopen</code> on Linux. Most kernels provide a custom function that fires when the shared library is loaded or unloaded, and these functions fall outside of the C++ standard, so there's no gaurantee about whether the static constructors have actually been called when you're inside the <code>DllLoad</code>, but almost nobody actually needs to worry about those edge cases, so for any normal code, by the time any function in your DLL can be called by another program, you can rest assured all static and global variables have had their constructors called. Likewise, they are destructed when the shared library is unloaded from memory.</p><p>While we're here, there are a few gotchas in the previous example that junior programmers should know about. You'll notice that I did not write <code><code>static Foo* = new GlobalFoo();</code></code> - <strong>this will leak memory!</strong>. In this case, C++ doesn't actually call the destructor because <code>Foo</code> doesn't have a static lifetime, <strong>the pointer it's stored in does!</strong>. So the <em>pointer</em> will get it's constructor called before the program starts (which does nothing, because it's a primitive), and then the pointer will have it's destructor called after <code>main()</code> returns, which also does nothing, which means <code>Foo</code> never actually gets deconstructed or deallocated. Always remember that C++ is <em>extremely</em> picky about what you do. C++ won't magically extend Foo's lifetime to the lifetime of the pointer, it will instead do <em>exactly</em> what you told it to do, which is to declare a global pointer primitive.</p><p>Another thing to avoid is to not accidentally write <code>Foo::instance.a = GlobalFoo.a;</code>, because this doesn't copy the integer, it copies <em>the pointer</em> from <code>GlobalFoo</code> to <code>Foo::instance</code>. This is extremely bad, because now <code>Foo::instance</code> will leak it's pointer and instead try to free <code>GlobalFoo</code>'s pointer, which was already deleted by <code>GlobalFoo</code>, so the program will crash, but only AFTER successfully returning 3. In fact, it will crash outside of the <code>main()</code> function completely, which is going to look very weird if you don't know what's going on.</p><h3 id=implicit-constructors-and-temporary-lifetimes>Implicit Constructors and Temporary Lifetimes</h3><p>Lifetimes in C++ can get complicated, because they don't just apply to function blocks, but also function parameters, return values, and expressions. This means that, for example, if we are calling a function, and we construct a new object inside the function call, there is an implicit lifetime that exists for the duration of the function call, which is well-defined but very weird unless you're aware of exactly what's going on. Let's look at a simple example of a function call that constructs an object:<pre class=language-cpp><code>class Foo
{
  // Implicit constructor for Foo
  Foo(int b)
  {
    a = b;
  }
  // Empty Destructor for Foo
  ~Foo() {}
  
  int a;
}

int get(Foo foo)
{
  return foo.a;
}

int main()
{
  return get(3);
}
</code></pre>To understand what's going on here, we need to understand <em>implicit constructors</em>, which are a &ldquo;feature&rdquo; of C++ you never wanted but got anyway. In C++, all constructors that take exactly 1 argument are <em>implicit</em>, which means the compiler will attempt to use call them to satisfy a type transformation. In this case, we are trying to pass <code>3</code> into the <code>get()</code> function. <code>3</code> has the type <code>int</code>, but <code>get()</code> takes an argument of type <code>Foo</code>. Normally, this would just cause an error, because the types don't match. But because we have a constructor for <code>Foo</code> that takes an <code>int</code>, the compiler actually calls it for us, constructing an object of type <code>Foo</code> and passing it into the function! Here's what it looks like if we do this ourselves:<pre class=language-cpp><code>int main()
{
  return get(Foo(3));
}
</code></pre>C++ has &ldquo;helpfully&rdquo; inserted this constructor for us inside the function call. So, now that we know our <code>Foo</code> object is being constructed inside the function call, we can ask a different question: When does the constructor get called, exactly? When is it destructed? The answer is that all the expressions in your function call are evaluated first, from left-to-right. Our expression allocated a new temporary <code>Foo</code> object by pushing it onto the stack and then calling the constructor. However, do be aware that compilers <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51253">aren't always so great about respecting initialization order</a> in function calls or other initialization lists. But, ostensibly, they're <em>supposed</em> to be evaluated from left-to-right.</p><p>So, once all expressions inside the parameteres have been evaluated, we then push the parameters on to the stack and copy the results of the expressions into them, allocate space on the stack for the return value, and then we enter the function. Our function executes, copies a return value into the space we reserved, finishes cleaning up, and returns. Then we do something with the return value and pop our parameters off the stack. Finally, after all the function parameter boilerplate has been finished, our expressions go out of scope in reverse order. This means that destructors are called from right-to-left after the function returns. This is all roughly equivilent to doing this:<pre class=language-cpp><code>int main()
{
  int b;
  {
    Foo a = Foo(3); // Construct Foo
    b = get(a); // Call function and copy result
  } // Deconstruct Foo
  return b;
}
</code></pre>This same logic works for all expressions - if you construct a temporary object inside an expression, it exists for the duration of the expression. However, the exact order that C++ evaluates expressions is <a href=https://en.cppreference.com/w/cpp/language/eval_order>extremely complicated and not always defined</a>, so this is a bit harder to nail down. Generally speaking, an object gets constructed right before it's needed to evaluate the expression, and gets deconstructed afterwards. These are &ldquo;temporary lifetimes&rdquo;, because the object only briefly exists inside the expression, and is deconstructed once the expression is evaluated. Because C++ expressions are not always ordered, you should not attempt to rely on any sort of constructor order for arbitrary expressions. As an example, we can inline our previous <code>get()</code> function:<pre class=language-cpp><code>int main()
{
  return Foo(3).a;
}
</code></pre>This will allocate a temporary object of type <code>Foo</code>, construct it with <code>3</code>, copy out the value from <code>a</code>, and then deconstruct the temporary object before the return statement is evaluated. For the most part, you can just assume your objects get constructed before the expression happens and get destructed after it happens - try not to rely on ordering more specific than that. The specific ordering rules are also changing in C++20 to make it more strict, which means how strict the ordering is will depend on what compiler you're using until everyone implements the standard properly.</p><p>For the record, if you don't want C++ &ldquo;helpfully&rdquo; turning your constructors into implicit ones, you can use the <code>explicit</code> keyword to disable that behavior:<pre class=language-cpp><code>struct Foo
{
  explicit Foo(int b)
  {
    a = b;
  }
  ~Foo() {}
  
  int a;
};
</code></pre></p><h3 id=static-variables-and-thread-local-lifetimes>Static Variables and Thread Local Lifetimes</h3><p>Static variables inside a function (not a struct!) operate by completely different rules, because this is C++ and consistency is for the weak.<pre class=language-cpp><code>struct Foo
{
  explicit Foo(int b)
  {
    a = b;
  }
  ~Foo() {}
  
  int a;
};

int get()
{
  static Foo foo(3);
  
  return foo.a;
}

int main()
{
  return get() + get();
}
</code></pre>When is <code>foo</code> constructed? It's not when the program starts - it's actually only constructed <em>the first time the function gets called</em>. C++ injects some magic code that stores a global flag saying whether or not the static variable has been initialized yet. The first time we call <code>get()</code>, it will be false, so the constructor is called and the flag is set to true. The second time, the flag is true, so the constructor isn't called. So when does it get destructed? After <code>main()</code> returns and the program is exiting, just like global variables!</p><p>Now, this static initialization <em>is</em> gauranteed to be thread-safe, but that's only useful if you intend to share the value through multiple threads, which usually doesn't work very well, because only the initialization is thread-safe, not accessing the variable. C++ has introduced a new lifetime called <code>thread_local</code> which is even weirder. Thread-local static variables only exist for the duration of the <em>thread</em> they belong to. So, if you have a thread-local static variable in a function, it's constructed the first time you call the function <em>on a per-thread basis</em>, and destroyed <em>when each thread exits</em>, not the program. This means you are gauranteed to have a unique instance of that static variable for each thread, which can be useful in certain concurrency situations.</p><p>I'm not going to spend any more time on <code>thread_local</code> because to understand it you really need to know how C++ concurrency works, which is out of scope for this blog post. Instead, let's take a brief look at Move Semantics.</p><h3 id=move-semantics>Move Semantics</h3><p>Let's look at C++'s smart pointer implementation, <code>unique_ptr&lt;></code>.<pre class=language-cpp><code>int get(int* b)
{
  return *b;
}

int main()
{
  std::unique_ptr&lt;int&gt; p(new int());
  *p = 3;
  int a = get(p.get());
  return a;
}
</code></pre>Here, we allocate a new integer on the heap by calling <code>new</code>, then store it in <code>unique_ptr</code>. This ensures that when our function returns, our integer gets freed and we don't leak memory. However, the lifetime of our pointer is actually excessively long - we don't need our integer pointer after we've extracted the value inside <code>get()</code>. What if we could change the lifetime of our pointer? The actual lifetime that we want is this:<pre class=language-cpp><code>int get(int* b)
{
  return *b;
  // We want the lifetime to end here
}

int main()
{
  // Lifetime starts here
  std::unique_ptr&lt;int&gt; p(new int());
  *p = 3;
  int a = get(p.get());
  return a;
  // Lifetime ends here
}
</code></pre>We can accomplish this by using <strong>move semantics</strong>:<pre class=language-cpp><code>int get(std::unique_ptr&lt;int&gt;&amp;&amp; b)
{
  return *b;
  // Lifetime of our pointer ends here
}

int main()
{
  // Lifetime of our pointer starts here
  std::unique_ptr&lt;int&gt; p(new int());
  *p                = 3;
  int a             = get(std::move(p));
  return a;
  // Lifetime of p ends here, but p is now empty
}
</code></pre>By using <code>std::move</code>, we <em>transfer ownership</em> of our unique_ptr to the function parameter. Now the <code>get()</code> function owns our integer pointer, so as long as we don't move it around again, it will go out of scope once <code>get()</code> returns, which will delete it. Our previous <code>unique_ptr</code> variable <code>p</code> is now empty, and when it goes out of scope, nothing happens, because it gave up ownership of the pointer it contained. This is how you can implement automatic memory management in C++ without needing to use a garbage collector, and Rust actually uses a more sophisticated version of this built into the compiler.</p><p>Move semantics can get very complex and have a lot of rules surrounding how temporary values work, but we're not going to get into all that right now. I also haven't gone into the many different ways that constructors can be invoked, and how those constructors interact with the <a href=https://blog.tartanllama.xyz/initialization-is-bonkers/>different ways you can initialize objects</a>. Hopefully, however, you now have a grasp of what lifetimes are in C++, which is a good jumping off point for learning about more advanced concepts.</p><hr><p><sup><a name=f1>[1]</a></sup> Pedantic assembly-code analysts will remind us that the stack allocations usually happen exactly once, at the beginning of the function, and then are popped off at the very end of the function, but the standard technically doesn't even require a stack to exist in the first place, so we're really talking about pushing and popping off the abstract stack concept that the language uses, not what the actual compiled assembly code really does.</p><p><sup><a name=f2>[2]</a></sup> We're <em>dereferencing</em> the pointer here because we want to return the <em>value</em> of the pointer, not the pointer itself! If you tried to return the pointer itself from the function, it would point to freed memory and crash after the function returned. Trying to return pointers from functions is a common mistake, so be careful if you find yourself returning a pointer to something. It's better to use <code>unique_ptr</code> to manage lifetimes of pointers for you.</p></div><hr><time itemprop=datePublished pubdate=pubdate datetime=2021-05-01T23:04:00+00:00><i class="fa fa-clock-o fa-fw"></i>&nbsp;Published on <a href=https://erikmcclure.com/blog/cpp-constructors-memory-and-lifetimes/>May 1, 2021 at 11:04pm</a></time><aside><a href=/blog/cpp-constructors-memory-and-lifetimes/#comments><i class="fa fa-comments-o fa-fw"></i>&nbsp;0 comments</a></aside><aside><i class="fa fa-share-square-o fa-fw"></i>&nbsp;share:<ul><li><a href="javascript:window.open('https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ferikmcclure.com%2fblog%2fcpp-constructors-memory-and-lifetimes%2f','popup','width=600,height=400');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" d="M16.75 9H13.5V7a1 1 0 011-1h2V3H14a4 4 0 00-4 4V9H8v3h2v9h3.5V12H16z"/></svg></a><li><a href="javascript:window.open('https://twitter.com/intent/tweet?text=C%2b%2b%20Constructors%2c%20Memory%2c%20and%20Lifetimes&url=https%3a%2f%2ferikmcclure.com%2fblog%2fcpp-constructors-memory-and-lifetimes%2f','popup','width=600,height=256');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" opacity="0" d="M0 0h24v24H0z"/><path class="st0" d="M23.643 4.937c-.835.37-1.732.62-2.675.733.962-.576 1.7-1.49 2.048-2.578-.9.534-1.897.922-2.958 1.13-.85-.904-2.06-1.47-3.4-1.47-2.572.0-4.658 2.086-4.658 4.66.0.364.042.718.12 1.06-3.873-.195-7.304-2.05-9.602-4.868-.4.69-.63 1.49-.63 2.342.0 1.616.823 3.043 2.072 3.878-.764-.025-1.482-.234-2.11-.583v.06c0 2.257 1.605 4.14 3.737 4.568-.392.106-.803.162-1.227.162-.3.0-.593-.028-.877-.082.593 1.85 2.313 3.198 4.352 3.234-1.595 1.25-3.604 1.995-5.786 1.995-.376.0-.747-.022-1.112-.065 2.062 1.323 4.51 2.093 7.14 2.093 8.57.0 13.255-7.098 13.255-13.254.0-.2-.005-.402-.014-.602.91-.658 1.7-1.477 2.323-2.41z"/></svg></a></li><li><a href="javascript:window.open('https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ferikmcclure.com%2fblog%2fcpp-constructors-memory-and-lifetimes%2f','popup','width=700,height=380');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><rect class="st0" height="11" width="4" x="3" y="9"/><circle class="st0" cx="5" cy="5" r="2"/><path class="st0" d="M16.5 8.25A4.47251 4.47251.0 0013 9.95343V9H9V20h4V13a2 2 0 014 0v7h4V12.75a4.5 4.5.0 00-4.5-4.5z"/></svg></a></li><li><a href="javascript:window.open('https://plus.google.com/share?app=110&url=https%3a%2f%2ferikmcclure.com%2fblog%2fcpp-constructors-memory-and-lifetimes%2f','popup','width=400,height=380');"><svg xmlns="http://www.w3.org/2000/svg" viewBox="4 2 52.6934 50.6934" class="icon-img" height="24"><style>.st0{fill:#666}</style><g><path class="st0" d="M19.6671 25.7867c-.0075 1.7935.0 3.5869.0076 5.3803 3.0067.098 6.0208.0527 9.0275.098-1.3262 6.6689-10.3989 8.8315-15.199 4.4761C8.5674 31.9206 8.801 23.5412 13.9327 19.992c3.5869-2.8635 8.6884-2.1552 12.2752.324 1.4092-1.3036 2.7278-2.6977 4.0013-4.1445-2.984-2.3812-6.6462-4.0767-10.5421-3.8958-8.1307-.2713-15.6059 6.8497-15.7415 14.9805-.52 6.6462 3.8506 13.1644 10.0222 15.5155 6.1489 2.3661 14.031.7535 17.957-4.77 2.5922-3.4889 3.1498-7.98 2.8484-12.1999C29.7194 25.7641 24.6933 25.7716 19.6671 25.7867z"/><path class="st0" d="M49.0704 25.7641c-.0151-1.4996-.0226-3.0067-.0301-4.5062-1.4996.0-2.9916.0-4.4836.0-.0151 1.4996-.0301 2.9991-.0377 4.5062-1.5071.0075-3.0067.0151-4.5062.0302.0 1.4995.0 2.9915.0 4.4836 1.4995.0151 3.0066.0302 4.5062.0452.0151 1.4996.0151 2.9991.0302 4.4987 1.4996.0 2.9916.0 4.4911.0.0075-1.4996.015-2.9991.0301-4.5062 1.5071-.0151 3.0067-.0226 4.5062-.0377.0-1.4921.0-2.9916.0-4.4836C52.0771 25.7792 50.57 25.7792 49.0704 25.7641z"/></g></svg></a></li></ul></aside></article><article><h4><a href=/blog/factorio-is-best-interview-we-have/>Factorio Is The Best Technical Interview We Have</a></h4><hr><div class=padding><p>There's been a lot of hand-wringing over The Technical Interview lately. Many people realize that inverting a binary tree on a whiteboard has basically zero correlation to whether or not someone is actually a good software developer. The most effective programming test anyone's come up with is still <a href=https://www.globalnerdy.com/2012/11/15/fizzbuzz-still-works/>Fizzbuzz</a>. One consequence of this has been an increased emphasis on Open Source Contributions, but it turns out <a href=https://blog.ploeh.dk/2021/03/22/the-dispassionate-developer/>these aren't a very good metric either</a>, because most people don't have that kind of time.</p><p>The most effective programming interview we have now is usually some kind of take-home project, where a candidate is asked to fix a bug or implement a small feature within a few days. This isn't great because it takes up a lot of time, and they could recieve outside help (or, if the feature is sufficiently common, google it). On the other hand, some large companies have instead doubled-down on whiteboard style interviews by subjecting prospective engineers to multiple hour-long online coding assessments, with varying levels of invasive surveillience.</p><p>All these interviewing methods pale in comparison to a very simple metric: <strong>playing Factorio with someone</strong>. Going through an entire run of Factorio is almost the best possible indication of how well someone deals with common technical problems. You can even tweak the playthrough based on the seniority of the position you're hiring for to get a better sense of how they'll function in that role.</p><h3 id=factorio>Factorio?</h3><p>Factorio is a game about automation. The best introduction is probably <a href="https://www.youtube.com/watch?v=KVvXv1Z6EY8">this trailer</a>, but in essence, your job is to build an automated factory capable of launching a rocket into space.</p><p>You begin with nothing. You mine stone manually to craft a smelter that can smelt iron ore you mined into iron plates, which you then use to build a coal-driven automatic miner. You could grab the iron ore from the miner and put it in the smelter yourself, but it's more efficient to use an inserter to do the inserting for you. Then you can use the iron this gives you to make another miner, which automates coal mining. Then you can use belts to take the coal and use an inserter to put it in the iron miner. Then you use the iron plates this tiny factory produces to make a third miner to start gathering copper, which then lets you craft copper wire, which lets you craft a circuit, which lets you build a water pump. Combined with a boiler and a steam engine, you can then build produce power, and use this power to run a research facility to unlock new technology, like assembly machines. Once you've unlocked assembly machines, you can use your circuits to craft an assembly machine that can craft copper wire for you, and insert this into an assembly machine that crafts circuits for you.</p><p>Eventually you unlock trains and robots and logistic systems which help you deal with the increasing logistic complexity the game demands, until you finally manage to launch a rocket into space.</p><h3 id=self-direction>Self-Direction</h3><p>The beginning of the game starts with no goals and barely any direction. A senior developer should be able to explore the UI and figure out a goal, then establish a plan for accomplishing that goal. A junior developer should be able to perform a task that a senior developer has provided for them. An intern is expected to require quite a bit of mentoring, but a junior developer should be able to troubleshoot basic problems with their own code before requiring assistance from the senior developer. An intermediate developer should be able to operate independently once given a task, but is not expected to do any architecture design.</p><p>In more concrete terms, you might expect the following:</p><ul><li>An <strong>Intern</strong> is generally expected to be able to fill in a pre-placed blueprint, and use belts to hook up their blueprint with something else, like an ore patch.</li><li>A <strong>Junior Developer</strong> should be able to build a production line by themselves, although it probably won't be very optimal. They may need assistance from the senior developer on how to route the belts properly to all of the intermediate assembly machines.</li><li>An <strong>Intermediate Developer</strong> should be capable of designing a near-optimal production line (without beacons) once given direction, with minimal oversight.</li><li>The <strong>Senior Developer</strong> needs no direction, and is capable of determining what goals need to happen and designing a plan of action, then delegating these tasks to other coders.</li></ul><h3 id=teamwork>Teamwork</h3><p>A critical aspect of software development is the ability to work on a team. This means coordinating your efforts with other people, accomadating the needs of other people's designs and cooperating with the team, instead of simply running off on your own and refusing to adjust your design to help integrate it with someone else's work. This, naturally, arises all the time in Factorio, because base layout designs are limited by physical space. As a result, you need to carefully consider what other people are doing, and sometimes adjust your design to fit in size constraints or deal with someone else's design that took more room than anticipated.</p><p>Anyone who simply runs off and starts doing things themselves or fixing problems without telling people is going to quickly earn the ire of their fellow players, for the exact same reasons cowboy programmers do. Luckily, Factorio includes a built-in equivelent to <code>git blame</code>, by showing you the last player that modified any entity. Thus, when people duct tape temporary solutions and don't inform the team about the problem they were fixing, when their temporary solution finally blows up, people will find out. If people want to win they game, they'll have to learn to cooperate well with their teammates.</p><h3 id=debugging>Debugging</h3><p>One of the most important skills for any programmer is their ability to debug problems. This is perhaps the most obvious parallel between Factorio and real software engineering. Something can go wrong very far away from the actual source of the problem. Being able to rapidly hone in on the real problem is a critical skill, and the thinking process is almost identical to tracing the cause of a crash in an actual program. If an assembly machine has stopped working, first you have to see if there are multiple outputs that got backed up. Then you have to check what ingredient it's missing. Then you have to trace the ingredient back through your factory to find out where you're making it, and repeat ad nauseum.</p><p>Factorio's debugging gets fairly complicated quite quickly. As soon as you start working on oil processing you'll be dealing with cracking, where you're dealing with 3 different outputs and if any of them get backed up for any reason, the entire thing stops. There are cases where your entire factory can grind to a halt because you started researching something that doesn't require yellow science, which stopped using up robot frames, which stopped using up electric engines, which stopped using lubricant, which stopped consuming heavy oil, which backed up and stopped oil production, which made you run out of petroleum, which broke plastic, which broke red circuits, which broke the rest of the factory. Seasoned players will anticipate scenarios like this and use circuits to construct self-balancing oil cracking to ensure the system is balanced and will only back up if petroleum backs up. A new player who is a good programmer, when presented with a factory that has collapsed, will usually be able to trace the issue back to the source, realize what's happened, and promptly attempt to figure out a solution. On the other hand, if someone simply plops down a few storage tanks, unless they can provide a good reason (they are very confident we will never stop consuming lubricant in the future), then this is a red flag for how they approach problem solving in their programs.</p><p>Situations like these allow Factorio to closely mimic the complex interdependencies that programmers routinely deal with, and the complexity simply increases the more gameplay concepts are added. This closely follows the increased complexity that additional layers of abstraction introduce when attempting to debug a crash that could have potentially occured deep inside one of the frameworks you use.</p><h3 id=code-reviews>Code Reviews</h3><p>Often, initial designs need to be tweaked for performance or throughput. Good programmers will not only accept critique of their designs, but incorporate that feedback into their future work. If they disagree with a proposed change, they will provide a concrete reason for why they disagree so that the team can more accurately weigh the pros and cons of the proposed change.</p><p>Resisting feedback without providing good reasons is a well-known red flag, but what can also be problematic is a programmer who begrudgingly accepts proposed changes, but refuses to adjust future designs accordingly. They end up requiring constant reminders to adhere to some standard way of solving a problem while giving no reason for why they don't seem to like the way the team is doing things. These can be ticking time-bombs in organizations, because when left unsupervised they can rapidly accumulate technical debt for other team members. This kind of problem is almost impossible to catch in a traditional interview, unless it's an internship.</p><h3 id=code-style-and-frameworks>Code Style and Frameworks</h3><p>Refusing to incorporate feedback is often just a slice of a much larger problem, where someone is unable to integrate properly into an existing framework being used. There are many ways to build a factory in Factorio, and each one requires standard methods of building pieces. Failing to adhere to standards can very quickly jam up an entire factory, often in subtle ways that aren't necessarily obvious to a careless developer.</p><p>In the Main Belt design, a set of 4-8 chunk of belts, divided by 2 spaces to allow for underground belts, are placed in the center of the factory, and all production happens perpendicular to the belt. This design relies on several rules that can wreck havoc if not followed correctly. One, players must always use a splitter to pull items off of a belt, never redirecting the entire belt, otherwise using the empty space for a different belt of items means you'll have permanently lost one entire belt of resources, even after upgrading belts. Two, all factories must be scalable in a direction perpendicular to the main belt. Failing to do this will rapidly result in either a massive waste of space, or a production line that cannot be scaled up because it's surrounded by other production lines.</p><p>There are also different ways of building logistic networks. The simplest method is with passive provider chests, but another method uses a storage chest with a filter, which is used to solve the trashed item problem. Both of these methods require properly setting limiters in the right location. Passive provider chests generally are limited by chest space. Storage chests require hooking the inserter for the chest up to the logistics network and ensuring that less than N of an item exists before inserting it. Forgetting to perform these limiting steps is a massive waste of resources. <em>Consistently</em> forgetting to put limiters on outputs is a red flag for someone who is careless about performance in real-world applications.</p><p>In other cases, the team may be using some pre-designed blueprints, like a nuclear reactor design, or a bot factory. These can be extremely complex, but as long as people are willing to learn how to use them, they can be huge time-savers. Beware of candidates who don't want to learn how to set up a new item in the bot factory simply because they can't debug the complex logic that drives it, or ones that get frustrated learning how to use a bot factory despite the clear and obvious benefits.</p><h3 id=multithreading>Multithreading</h3><p>Trains in Factorio are a direct analogue to multithreading: one train is one thread of execution, and each train intersection or train stop is a place in memory where two threads could potentially write at the same time. Train signals are locks, or mutexes. All bugs in train networks manifest in exactly the same way software race conditions do, because they're literally physical race conditions. All of the tradeoffs apply here as well - if you make a lock too large, it slows down your throughput, because now the intersection is blocked for a longer period of time. Incorrectly signaled tracks routinely cause train deadlocks that are exactly the same as a software deadlock, because you end up with a circular lock dependency. The most common deadlock is when a train is too long and unexpectedly blocks a second intersection while waiting to enter one. This second intersection then prevents another train from leaving, preventing the first intersection from ever being unblocked.</p><p>The number of lanes of track in your network is equivilent to the number of cores available in your CPU. A single rail line is difficult to scale beyond a few threads because the entire system gets throughput limited very quickly, even with wait areas. The most common design is a two-lane design where each lane is a single direction, but this will eventually suffer from throughput issues when you need trains constantly being unloaded. Thus, large bases tend to have at least 4 lanes, with two outer lanes acting as bypasses to avoid the intersection whenever possible.</p><p>Missing signal problems in these systems can take a ridiculous amount of time to actually show up. A single missing signal in one rail network once caused a deadlock after functioning correctly for <em>two weeks</em>. This is remniscient of difficult to pin down race conditions in software that only occur once a month or so when under high contention.</p><h3 id=scaling>Scaling</h3><p>Just like in software, scaling up production in Factorio introduces new problems with initial designs, and often require complete redesigns that can pipe resources into factories as fast as possible, while taking advange of production modules and speed module beacons. Belt limits become problematic even at the fastest belt speed, forcing players to find ways to split designs up so that more belts can be put in later down the line, or split up their factories into modules.</p><p>Handling your logistics network itself becomes a logistics problem in the late game because of how problematic expansive bot networks are. You generally need to start segmenting the logistics network and either using trains to transport items between them, or build a requester chest/provider chest that propagates items across bounderies.</p><p>Managing trains in the late game necessitates switching to a pull architecture from a push architecture, because the push architecture can't function in high throughput. This inevitably requires taking advantage of the Train Limits feature and learning how circuit networks can be used to encode basic logic, such that a station only requests a train when it is actually ready to completely fill the train with resources, instead of the common early game tactic of simply telling a bunch of trains to go to stations named &ldquo;Iron Pickup&rdquo;. This minimizes the number of trains you need while making sure all stops are served on the network.</p><p>Often times, limitations in the number of possible inputs to an assembly machine and inserter speed require redesigning factories around them, just like how high-speed computing requires being aware of subtle bottlenecks in how your CPU works. These bottlenecks are almost never a problem until you reach a certain scale, at which point they begin to dominate your efficiency.</p><h3 id=microservices-and-plugin-architectures>Microservices and Plugin Architectures</h3><p>Eventually, factories get so enormous they must abandon a simple main belt or spaghetti design and use a more scalable framework instead. To reach Megabase-scale, factories generally either use a train system or a module system, which corresponds roughly to microservices or a plugin-architecture.</p><p>A train-based megabase is sometimes referred to a &ldquo;city-block&rdquo; design, where trains surrounded factory blocks and control all input and output. Thus, each individual city-block is isolated from all other city-blocks, since all their input is &ldquo;pure&rdquo; in that it comes from the train network. This is almost identical to a micro-services architecture (over HTTP) or a multi-process design (using IPC), and has similar potential issues with input and output latency, because results cannot be continually provided, they must be emitted in &ldquo;packets&rdquo;, or trains along the network.</p><p>The plugin architecture seeks to maintain some semblence of a main-belt, but instead splits belts off through the factory and uses modular blocks that take standard inputs and standard outputs. Sometimes this can be achieved entirely through bots, but materials usually need to be belted over long distances. This closely resembles a plugin system for a monolithic application, and has similar tradeoffs.</p><p>These megabases mark the extreme upper end of a vanilla Factorio server. However, there are plenty of mods to make things much more complex.</p><h3 id=distributed-systems>Distributed Systems</h3><p><a href=https://mods.factorio.com/mod/space-exploration>Space Exploration</a> is an overhaul of Factorio that adds an entire space segment of the game, and makes planets have limited resources, requiring players to colonize other planets and use rockets to transfer resources between planets. Because of the enormous latency involved with shipping materials between planets, coordinating these different bases winds up having similar problems to a globally distributed database system. Even the circuit network has to contend with latency, because an automatic request system loses track of items that have been launched but haven't yet reached the target planet. Not accounting for this will result in a <em>double-request</em> for all the items you wanted, which is the <em>exact same problem</em> that distributed systems have when trying to ensure consistency.</p><h3 id=conclusion>Conclusion</h3><p>Collectively, the software industry simply has no idea how to hire software developers. Factorio is probably the best technical interview we have right now, and <em>that's embarassing</em>. It is also wildly impractical, taking over 20 hours in an initial multiplayer playthrough, or 8 hours if you have a lot of people and know what you're doing. What's the takeaway from this? I don't know. We certainly can't switch to using Factorio as an interviewing method - you might as well just give a candidate a take-home assignment.</p><p>At the very least, we can do better than whiteboard interviews.</p></div><hr><time itemprop=datePublished pubdate=pubdate datetime=2021-03-12T15:26:00+00:00><i class="fa fa-clock-o fa-fw"></i>&nbsp;Published on <a href=https://erikmcclure.com/blog/factorio-is-best-interview-we-have/>March 12, 2021 at 3:26pm</a></time><aside><a href=/blog/factorio-is-best-interview-we-have/#comments><i class="fa fa-comments-o fa-fw"></i>&nbsp;0 comments</a></aside><aside><i class="fa fa-share-square-o fa-fw"></i>&nbsp;share:<ul><li><a href="javascript:window.open('https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ferikmcclure.com%2fblog%2ffactorio-is-best-interview-we-have%2f','popup','width=600,height=400');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" d="M16.75 9H13.5V7a1 1 0 011-1h2V3H14a4 4 0 00-4 4V9H8v3h2v9h3.5V12H16z"/></svg></a><li><a href="javascript:window.open('https://twitter.com/intent/tweet?text=Factorio%20Is%20The%20Best%20Technical%20Interview%20We%20Have&url=https%3a%2f%2ferikmcclure.com%2fblog%2ffactorio-is-best-interview-we-have%2f','popup','width=600,height=256');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" opacity="0" d="M0 0h24v24H0z"/><path class="st0" d="M23.643 4.937c-.835.37-1.732.62-2.675.733.962-.576 1.7-1.49 2.048-2.578-.9.534-1.897.922-2.958 1.13-.85-.904-2.06-1.47-3.4-1.47-2.572.0-4.658 2.086-4.658 4.66.0.364.042.718.12 1.06-3.873-.195-7.304-2.05-9.602-4.868-.4.69-.63 1.49-.63 2.342.0 1.616.823 3.043 2.072 3.878-.764-.025-1.482-.234-2.11-.583v.06c0 2.257 1.605 4.14 3.737 4.568-.392.106-.803.162-1.227.162-.3.0-.593-.028-.877-.082.593 1.85 2.313 3.198 4.352 3.234-1.595 1.25-3.604 1.995-5.786 1.995-.376.0-.747-.022-1.112-.065 2.062 1.323 4.51 2.093 7.14 2.093 8.57.0 13.255-7.098 13.255-13.254.0-.2-.005-.402-.014-.602.91-.658 1.7-1.477 2.323-2.41z"/></svg></a></li><li><a href="javascript:window.open('https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ferikmcclure.com%2fblog%2ffactorio-is-best-interview-we-have%2f','popup','width=700,height=380');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><rect class="st0" height="11" width="4" x="3" y="9"/><circle class="st0" cx="5" cy="5" r="2"/><path class="st0" d="M16.5 8.25A4.47251 4.47251.0 0013 9.95343V9H9V20h4V13a2 2 0 014 0v7h4V12.75a4.5 4.5.0 00-4.5-4.5z"/></svg></a></li><li><a href="javascript:window.open('https://plus.google.com/share?app=110&url=https%3a%2f%2ferikmcclure.com%2fblog%2ffactorio-is-best-interview-we-have%2f','popup','width=400,height=380');"><svg xmlns="http://www.w3.org/2000/svg" viewBox="4 2 52.6934 50.6934" class="icon-img" height="24"><style>.st0{fill:#666}</style><g><path class="st0" d="M19.6671 25.7867c-.0075 1.7935.0 3.5869.0076 5.3803 3.0067.098 6.0208.0527 9.0275.098-1.3262 6.6689-10.3989 8.8315-15.199 4.4761C8.5674 31.9206 8.801 23.5412 13.9327 19.992c3.5869-2.8635 8.6884-2.1552 12.2752.324 1.4092-1.3036 2.7278-2.6977 4.0013-4.1445-2.984-2.3812-6.6462-4.0767-10.5421-3.8958-8.1307-.2713-15.6059 6.8497-15.7415 14.9805-.52 6.6462 3.8506 13.1644 10.0222 15.5155 6.1489 2.3661 14.031.7535 17.957-4.77 2.5922-3.4889 3.1498-7.98 2.8484-12.1999C29.7194 25.7641 24.6933 25.7716 19.6671 25.7867z"/><path class="st0" d="M49.0704 25.7641c-.0151-1.4996-.0226-3.0067-.0301-4.5062-1.4996.0-2.9916.0-4.4836.0-.0151 1.4996-.0301 2.9991-.0377 4.5062-1.5071.0075-3.0067.0151-4.5062.0302.0 1.4995.0 2.9915.0 4.4836 1.4995.0151 3.0066.0302 4.5062.0452.0151 1.4996.0151 2.9991.0302 4.4987 1.4996.0 2.9916.0 4.4911.0.0075-1.4996.015-2.9991.0301-4.5062 1.5071-.0151 3.0067-.0226 4.5062-.0377.0-1.4921.0-2.9916.0-4.4836C52.0771 25.7792 50.57 25.7792 49.0704 25.7641z"/></g></svg></a></li></ul></aside></article><div class=pager><ul><li class=disabled><a title="No newer posts">Newer</a></li><li style=text-align:center><a href=/blog/>Home</a></li><li style=text-align:right><a href=/blog/page/2>Older</a></li></ul></div></section><section class=archive><article><img src=https://erikmcclure.com/img/avatar.th.png alt=Avatar width=180 height=180><h2>Archive</h2><ol><li><details><summary>2022</summary><ul><li><a href=/blog/windows-malloc-implementation-is-a-trash-fire/>The Windows malloc() Implementation Is A Trash Fire</a></li><li><a href=/blog/camp-vista/>Camp Vista - Growing Up Next To Microsoft</a></li></ul></details></li><li><details><summary>2021</summary><ul><li><a href=/blog/blockchain-new-javascript/>Blockchain Is The New JavaScript</a></li><li><a href=/blog/cpp-constructors-memory-and-lifetimes/>C++ Constructors, Memory, and Lifetimes</a></li><li><a href=/blog/factorio-is-best-interview-we-have/>Factorio Is The Best Technical Interview We Have</a></li></ul></details></li><li><details><summary>2020</summary><ul><li><a href=/blog/why-you-cant-use-prebuilt-llvm-with-cpp17/>Why You Can't Use Prebuilt LLVM 10.0 with C++17</a></li><li><a href=/blog/someone-is-stealing-tracker-songs/>Someone Is Stealing Tracker Songs And Selling Them</a></li><li><a href=/blog/pressure-based-anti-spam-for-discord-bots/>Pressure Based Anti-Spam for Discord Bots</a></li></ul></details></li><li><details><summary>2019</summary><ul><li><a href=/blog/name-shadowing-should-be-an-operator/>Name Shadowing Should Be An Operator</a></li><li><a href=/blog/a-rant-on-terra/>A Rant On Terra</a></li><li><a href=/blog/risc-is-fundamentally-unscalable/>RISC Is Fundamentally Unscalable</a></li></ul></details></li><li><details><summary>2018</summary><ul><li><a href=/blog/software-engineering-is-bad-but-it-s-not-that-bad/>Software Engineering Is Bad, But That's Not Why</a></li><li><a href=/blog/why-do-people-use-the-wrong-email-/>Why Do People Use The Wrong Email?</a></li><li><a href=/blog/software-optimizes-to-single-points-of-failure/>Software Optimizes to Single Points of Failure</a></li><li><a href=/blog/migrating-to-static-blog/>Migrating To A Static Blog</a></li><li><a href=/blog/how-to-avoid-memorizing-times-tables/>How To Avoid Memorizing Times Tables</a></li></ul></details></li><li><details><summary>2017</summary><ul><li><a href=/blog/ignoring-outliers-creates-racist/>Ignoring Outliers Creates Racist Algorithms</a></li><li><a href=/blog/i-used-to-want-to-work-for-google/>I Used To Want To Work For Google</a></li><li><a href=/blog/sexist-programmers-are-awful-engineers/>Sexist Programmers Are Awful Engineers</a></li><li><a href=/blog/why-i-never-built-my-soundcloud-killer/>Why I Never Built My SoundCloud Killer</a></li><li><a href=/blog/integrating-luajit-and-autogenerating-c/>Integrating LuaJIT and Autogenerating C Bindings In Visual Studio</a></li><li><a href=/blog/discord-rise-of-bot-wars/>Discord: Rise Of The Bot Wars</a></li><li><a href=/blog/programmers-should-take-linguistics/>Programmers Should Take Linguistics</a></li><li><a href=/blog/companies-cant-be-apolitical/>Companies Can't Be Apolitical</a></li><li><a href=/blog/i-cant-hear-anything-below-80-hz/>I Can't Hear Anything Below 80 Hz*</a></li><li><a href=/blog/windows-wont-let-my-program-crash/>Windows Won't Let My Program Crash</a></li><li><a href=/blog/directx-is-terrifying/>DirectX Is Terrifying</a></li><li><a href=/blog/our-software-is-beacon-of-hope/>Our Software Is a Beacon of Hope</a></li></ul></details></li><li><details><summary>2016</summary><ul><li><a href=/blog/everyone-does-srgb-wrong-because/>Everyone Does sRGB Wrong Because Everyone Else Does sRGB Wrong</a></li><li><a href=/blog/mathematical-notation-is-awful/>Mathematical Notation Is Awful</a></li><li><a href=/blog/the-gpl-is-usually-overkill/>The GPL Is Usually Overkill</a></li><li><a href=/blog/the-right-to-ignore-difference-between/>The Right To Ignore: The Difference Between Free Speech And Harassment</a></li></ul></details></li><li><details><summary>2015</summary><ul><li><a href=/blog/there-will-never-be-one-true/>There Will Never Be One True Programming Language</a></li><li><a href=/blog/abortion-has-no-moral-high-ground/>Abortion Has No Moral High Ground</a></li><li><a href=/blog/i-tried-to-install-linux-and-now-i/>I Tried To Install Linux And Now I Regret Everything</a></li><li><a href=/blog/you-arent-designing-software-for-robots/>We Aren't Designing Software For Robots</a></li><li><a href=/blog/using-data-to-balance-your-game-pony/>Using Data To Balance Your Game: Pony Clicker Analysis</a></li><li><a href=/blog/is-there-commercial-open-source-license/>Is There A Commercial Open Source License?</a></li><li><a href=/blog/does-anyone-actually-want-good-software/>Does Anyone Actually Want Good Software?</a></li><li><a href=/blog/why-dont-you-just-fire-them/>Why Don't You Just Fire Them?</a></li></ul></details></li><li><details><summary>2014</summary><ul><li><a href=/blog/how-not-to-sell-software/>How Not To Install Software</a></li><li><a href=/blog/not-reinventing-wheel-is-anticompetitive/>Never Reinventing The Wheel Is Anticompetitive</a></li><li><a href=/blog/everyone-can-be-above-average/>Everyone Can Be Above Average</a></li><li><a href=/blog/can-we-choose-what-we-enjoy/>Can We Choose What We Enjoy?</a></li><li><a href=/blog/how-to-make-your-profiler-10x-faster/>How To Make Your Profiler 10x Faster</a></li><li><a href=/blog/the-problem-with-photorealism/>The Problem With Photorealism</a></li><li><a href=/blog/success-is-relative/>Success Is Relative</a></li></ul></details></li><li><details><summary>2013</summary><ul><li><a href=/blog/googles-decline-really-bugs-me/>Google's Decline Really Bugs Me</a></li><li><a href=/blog/the-educational-imbroglio/>The Educational Imbroglio</a></li><li><a href=/blog/the-ladder-climbing-generation/>The Ladder-Climbing Generation</a></li><li><a href=/blog/the-microsoft-word-problem/>The Microsoft Word Problem</a></li><li><a href=/blog/write-less-code/>Write Less Code</a></li><li><a href=/blog/most-people-have-shitty-computers/>Most People Have Shitty Computers</a></li><li><a href=/blog/leap-motion-impressions-input/>Leap Motion Impressions, Input Sanitation, and 3D Gesture Ideas</a></li><li><a href=/blog/aurora-theory-released/>Aurora Theory Released!</a></li><li><a href=/blog/what-i-learned-in-college/>What I Learned In College</a></li><li><a href=/blog/how-to-complain-about-men-and-be-sexist/>How To Complain About Men And Be Sexist At The Same Time</a></li><li><a href=/blog/course-notes/>Course Notes</a></li><li><a href=/blog/contact/>Contact</a></li><li><a href=/blog/the-dark-side-of-htmlcss/>The Dark Side of Web Development</a></li><li><a href=/blog/windows-breaks-assert-inside/>Windows Breaks assert() Inside WM_CANCELMODE</a></li><li><a href=/blog/dreams-are-worth-fighting-for/>Dreams Are Worth Fighting For</a></li><li><a href=/blog/the-productivity-fallacy/>The Productivity Fallacy</a></li><li><a href=/blog/the-earbud-loudness-wars/>The Earbud Loudness Wars</a></li></ul></details></li><li><details><summary>2012</summary><ul><li><a href=/blog/giant-list-of-free-samples/>Giant List of FREE SAMPLES</a></li><li><a href=/blog/the-weekend-apelsin-got-lost-all-time/>The Weekend I Got Lost All The Time</a></li><li><a href=/blog/c-to-c-tutorial-part-4-operator-overload/>C# to C++ Tutorial - Part 4: Operator Overload</a></li><li><a href=/blog/7-problems-raytracing-doesnt-solve/>7 Problems Raytracing Doesn't Solve</a></li><li><a href=/blog/teenage-rebellion-as-failure-of-society/>Teenage Rebellion as a Failure of Society</a></li><li><a href=/blog/analyzing-xkcd-click-and-drag/>Analyzing XKCD: Click and Drag</a></li><li><a href=/blog/what-is-right-answer/>What Is A Right Answer?</a></li><li><a href=/blog/coordinate-systems-and-cascading/>Coordinate Systems And Cascading Stupidity</a></li><li><a href=/blog/how-joysticks-ruined-my-graphics-engine/>How Joysticks Ruined My Graphics Engine</a></li><li><a href=/blog/properly-dreaming-about-success/>Properly Dreaming About Success</a></li><li><a href=/blog/multithreading-problems-in-game-design/>Multithreading Problems In Game Design</a></li><li><a href=/blog/ip-law-makes-you-asshole/>IP Law Makes You an Asshole</a></li><li><a href=/blog/stop-following-rules/>Stop Following The Rules</a></li><li><a href=/blog/standards-problem/>The Standards Problem</a></li><li><a href=/blog/an-evidence-based-refutation-of-the-project-glass-parodies/>An evidence-based refutation of the Project Glass parodies</a></li><li><a href=/blog/language-wars-are-pointless/>Language Wars Are Pointless</a></li><li><a href=/blog/why-windows-8-does-right-thing-wrong/>Why Windows 8 Does The Right Thing The Wrong Way</a></li><li><a href=/blog/well-that-was-interesting/>Well That Was Interesting</a></li><li><a href=/blog/visual-studio-broke-my-computer/>Visual Studio Broke My Computer</a></li><li><a href=/blog/hiring-wrong-people/>Hiring the Wrong People</a></li><li><a href=/blog/chill-out/>Chill Out</a></li><li><a href=/blog/implicit-ui-design/>Implicit UI Design</a></li><li><a href=/blog/linux-mint-12-kde/>Linux Mint 12 KDE</a></li><li><a href=/blog/new-post/>'Programmer' is an Overgeneralization</a></li><li><a href=/blog/wikipedias-identity-crisis/>Wikipedia's Identity Crisis</a></li></ul></details></li><li><details><summary>2011</summary><ul><li><a href=/blog/your-esoteric-language-is-useless/>Your Esoteric Language is Useless</a></li><li><a href=/blog/great-mystery-of-linear-gradient/>The Great Mystery of Linear Gradient Lighting</a></li><li><a href=/blog/signed-integers-considered-stupid-like/>Signed Integers Considered Stupid (Like This Title)</a></li><li><a href=/blog/why-kids-hate-math/>Why Kids Hate Math</a></li><li><a href=/blog/importance-of-importance/>Don't Work on Someone Else's Dream</a></li><li><a href=/blog/c-to-c-tutorial-part-3-classes-and/>C# to C++ Tutorial - Part 3: Classes and Structs and Inheritance (OH MY!)</a></li><li><a href=/blog/problem-of-vsync/>The Problem of Vsync</a></li><li><a href=/blog/musical-genres/>Musical Genres</a></li><li><a href=/blog/c-to-c-tutorial-part-2-pointers/>C# to C++ Tutorial - Part 2: Pointers Everywhere!</a></li><li><a href=/blog/radians-explanation/>Radians: An explanation</a></li><li><a href=/blog/c-to-c-tutorial-part-1-basics-of-syntax/>C# to C++ Tutorial - Part 1: Basics of Syntax</a></li><li><a href=/blog/on-hackers/>On Hacking (or Why We Need Security Ratings)</a></li><li><a href=/blog/my-mom-had-heart-attack/>My Mom Had a Heart Attack</a></li><li><a href=/blog/religion-problem-perspectives/>The Religion Problem: Perspectives</a></li><li><a href=/blog/ninth-circle-of-bugs/>The Ninth Circle of Bugs</a></li><li><a href=/blog/save-rss/>Save RSS</a></li><li><a href=/blog/college-is-broken/>College Is Broken</a></li><li><a href=/blog/outside-perspective-on-psn-fiasco/>An Outside Perspective on the PSN Fiasco</a></li><li><a href=/blog/future-predictions/>Future Predictions</a></li><li><a href=/blog/investigating-low-level-cpu-performance/>Investigating Low-level CPU Performance</a></li><li><a href=/blog/bullying-never-stops/>The Bullying Never Stops</a></li></ul></details></li><li><details><summary>2010</summary><ul><li><a href=/blog/aquaria-hints/>Aquaria Hints</a></li><li><a href=/blog/im-failure/>The IM Failure</a></li><li><a href=/blog/how-to-train-your-dragon/>How To Train Your Dragon</a></li><li><a href=/blog/album-for-sale-renascent/>Album For Sale! [Renascent]</a></li><li><a href=/blog/wavsaver/>WavSaver</a></li><li><a href=/blog/pixel-perfect-hit-testing/>Pixel Perfect Hit Testing</a></li><li><a href=/blog/fractal-cycle-screensaver/>Fractal Cycle Screensaver</a></li><li><a href=/blog/8-bit-color-cycling/>8-bit color cycling</a></li><li><a href=/blog/physics-networking/>Physics Networking</a></li><li><a href=/blog/assembly-cas-implementation/>Assembly CAS implementation</a></li><li><a href=/blog/function-pointer-speed/>Function Pointer Speed</a></li><li><a href=/blog/most-bizarre-error-ever/>Most Bizarre Error Ever</a></li><li><a href=/blog/floating-point-preformance/>Floating Point Preformance</a></li><li><a href=/blog/watch-this-now/>Watch This Now</a></li></ul></details></li><li><details><summary>2009</summary><ul><li><a href=/blog/physics-oriented-network-interpolation/>Physics-oriented Network Interpolation</a></li><li><a href=/blog/proving-strong-ai/>Proving Strong AI</a></li><li><a href=/blog/i-now-have-lj/>I now have an LJ</a></li></ul></details></li></ol></article></section></main><footer><p><span>Copyright &copy;2022 Erik McClure</span> <a href=https://erikmcclure.com/sitemap.xml>Sitemap</a> | <a href=https://erikmcclure.com/blog/index.xml>RSS Feed</a></p></footer></div><script>"use strict";window.onload=function(){var t=document.getElementsByClassName('math');for(var i=0,len=t.length;i<len;i++){renderMathInElement(t[i],{delimiters:[{left:"$$",right:"$$",display:false},{left:"\\[",right:"\\]",display:true}]});}}</script></body></html>