<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=Edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#2b7bb5"><meta name=copyright content="Copyright (c)2020 Erik McClure"><meta name=keywords content="games,music,code,erik mcclure,erikmcclure,aurora theory,sweetie bot,discord,feathergui,black sphere studios,tinyoal,upatch"><meta name=robots content="index,follow"><meta name=googlebot content="index,follow"><meta name=google-site-verification content="Oxb2ia8HjcHLXlvstA8xPpQO3BO_y15Ds2Ia-feq1MQ"><meta name=generator content="Hugo 0.62.2"><link rel=canonical href=https://erikmcclure.com/blog/memory-management-on-modern-cpus/><link rel=apple-touch-icon href=https://erikmcclure.com/favicon.ico><link rel="shortcut icon" type=image/x-icon href=https://erikmcclure.com/favicon.ico><link rel=stylesheet href=https://erikmcclure.com/css/main.css><link rel=stylesheet href=https://erikmcclure.com/css/prism.css rel=stylesheet><link rel=stylesheet href=https://erikmcclure.com/css/katex.min.css rel=stylesheet><link rel=stylesheet href=https://erikmcclure.com/css/font-awesome.min.css><link rel=alternate type=application/rss+xml title="Erik McClure - RSS" href=https://erikmcclure.com/index.xml><meta property="og:type" content="article"><title>Memory Management on Modern CPUs</title><meta property="og:title" content="Memory Management on Modern CPUs"><meta name=twitter:title content="Memory Management on Modern CPUs"><meta itemprop=name content="Memory Management on Modern CPUs"><meta name=description content="The following post is going to make very little sense:
Modern CPUs have started to branch out into parallelism and increased cache size due to their inability to decrease latency, since electricity can only travel so fast. A signal from one side of the CPU can no longer get to the other side in a single cycle. This has led to an exponential increase in cache size and other bizarre optimizations, such as the CPU attempting to guess what the code is going to do."><meta property="og:description" content="The following post is going to make very little sense:
Modern CPUs have started to branch out into parallelism and increased cache size due to their inability to decrease latency, since electricity can only travel so fast. A signal from one side of the CPU can no longer get to the other side in a single cycle. This has led to an exponential increase in cache size and other bizarre optimizations, such as the CPU attempting to guess what the code is going to do."><meta name=twitter:description content="The following post is going to make very little sense:
Modern CPUs have started to branch out into parallelism and increased cache size due to their inability to decrease latency, since electricity can only travel so fast. A signal from one side of the CPU can no longer get to the other side in a single cycle. This has led to an exponential increase in cache size and other bizarre optimizations, such as the CPU attempting to guess what the code is going to do."><meta itemprop=description content="The following post is going to make very little sense:
Modern CPUs have started to branch out into parallelism and increased cache size due to their inability to decrease latency, since electricity can only travel so fast. A signal from one side of the CPU can no longer get to the other side in a single cycle. This has led to an exponential increase in cache size and other bizarre optimizations, such as the CPU attempting to guess what the code is going to do."><meta property="og:url" content="https://erikmcclure.com/"><meta property="og:site_name" content="Erik McClure"><meta property="og:image" content="https://erikmcclure.com/img/avatar.png"><meta property="og:locale" content="en-US"><meta property="article:author" content="Erik McClure"><meta name=twitter:card content="summary"><meta name=twitter:site content="@erikmcclure0173"><meta name=twitter:creator content="@erikmcclure0173"><meta name=twitter:image content="https://erikmcclure.com/img/avatar.png"><meta name=twitter:dnt content="on"><link href=https://plus.google.com/104896885003230920472 rel=publisher><meta itemprop=image content="https://erikmcclure.com/img/avatar.png"><meta name=last-updated content="20091205-16:28:00.000"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-63026815-3"></script><script defer src=https://erikmcclure.com/syntax-prism.js></script><script defer src=https://erikmcclure.com/katex.min.js></script><script defer src=https://erikmcclure.com/mathtex-script-type.min.js></script><script defer src=https://erikmcclure.com/auto-render.min.js></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-63026815-3');</script></head><body><div id=container><header><nav><ul><li><a href=/blog/ title=Blog><i class="fa fa-book fa-fw fa-lg"></i>&nbsp;<p>Blog</p></a></li><li><a href=/projects/ title=Projects><i class="fa fa-briefcase fa-fw fa-lg"></i>&nbsp;<p>Projects</p></a></li><li><a href=https://erikmcclure.bandcamp.com title=Bandcamp><i class="fa fa-bandcamp fa-fw fa-lg"></i>&nbsp;<p>Bandcamp</p></a></li><li><a href=https://github.com/erikmcclure title=Github><i class="fa fa-github fa-fw fa-lg"></i>&nbsp;<p>Github</p></a></li><li><a href=https://linkedin.com/in/erikmcclure/ title=LinkedIn><i class="fa fa-linkedin fa-fw fa-lg"></i>&nbsp;<p>LinkedIn</p></a></li><li><a href=/web/ title=Websites><i class="fa fa-globe fa-fw fa-lg"></i>&nbsp;<p>Websites</p></a></li></ul></nav><div class=dim><h1>Erik McClure</h1></div></header><main class=blog><section><meta itemprop=mainEntityOfPage itemtype=https://schema.org/WebPage content="https://erikmcclure.com/"><meta itemprop=dateModified content="2009-12-05T16:28:00+00:00"><meta itemprop=headline content="Memory Management on Modern CPUs"><meta itemprop=description content="The following post is going to make very little sense:
Modern CPUs have started to branch out into parallelism and increased cache size due to their inability to decrease latency, since electricity can only travel so fast. A signal from one side of the CPU can no longer get to the other side in a single cycle. This has led to an exponential increase in cache size and other bizarre optimizations, such as the CPU attempting to guess what the code is going to do."><meta itemprop=url content="https://erikmcclure.com/blog/memory-management-on-modern-cpus/"><div itemprop=publisher itemscope itemtype=https://schema.org/Organization><div itemprop=logo itemscope itemtype=https://schema.org/ImageObject><meta itemprop=url content="https://erikmcclure.com/img/avatar.png"><meta itemprop=width content="140"><meta itemprop=height content="140"></div><meta itemprop=name content="Erik McClure"></div><div itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=name content="Erik McClure"></div><article><h4>Memory Management on Modern CPUs</h4><hr><div class=padding><p>The following post is going to make very little sense:</p><p>Modern CPUs have started to branch out into parallelism and increased cache size due to their inability to decrease latency, since electricity can only travel so fast. A signal from one side of the CPU can no longer get to the other side in a single cycle. This has led to an exponential increase in cache size and other bizarre optimizations, such as the CPU attempting to guess what the code is going to do. In some cases the CPU might even decide to do something completely different then what the assembly told it to do just for the sake of speed, which can introduce serious issues for threading. The cache, however, is what we are concerned with. L1 cache takes 2 cycles, L2 takes about 14 cycles, and I don't know what L3 takes but its probably somewhere around 50. RAM on the other hand takes, on average, nearly <strong>200 cycles</strong>. This means that cache misses are ridiculously expensive and made even worse by the fact that you can't really be sure that the CPU is actually doing what you're telling it to do. There's little we can do about the CPU running off with your code, but we can help it along by paying attention to data locality.</p><p>Linked lists have long had issues with data locality, and this makes it even more obvious. However, the answer isn't immediately obvious. We could switch over to vectors and arrays, sure, but in practice these incur even worse overheads when you simply iterate through them. One solution here is to combine the two - make a linked list that's a vector. However, while that does achieve what we're doing here, there is an even better, if slightly more complicated solution.</p><p>The number one slowdown in any program is memory allocation. If you aren't allocating something on the stack, it will likely cost as much time just to allocate a tiny chunk of memory then your entire function's execution time. This actually gets to the point of total absurdity when dealing with rapidly allocated and de-allocated small chunks of memory. In one example, a 2D graphics engine must assemble a list of pictures that are sorted by an optimization function, every single frame. If you even attempt to do this with the default memory allocation, it slows the application down to an absolute crawl. If, however, we implement our own memory management, the speed increases are somewhere around <strong>%15000</strong>. No, I'm not kidding, and yes, that is based off real-world testing.</p><p>The general attitude of the C++ community is that home-baked memory allocators are overkill, but as CPU technology advances, it turns out that in practice, the opposite is true. The default allocator was built in the 1990s and on modern architecture is pathetically slow. This, however, does not have to be a necessity. I have built several allocators for my graphics engine and every single one of them has increased performance by a factor of at least 2. The sheer amount of speed that can be gained from custom memory allocators is astounding, and there is a reason for it.</p><p>Custom memory allocators have a very distinct feature - they often concentrate a single class type into one compressed memory allocation space. When used with in conjunction with linked lists we get the best of both worlds, especially since when we free the memory, <em>we aren't actually freeing the memory</em>. We're just marking it as unused and then using it again next time we need it. Obviously I've only used this in situations where its obvious that the memory will be needed again very soon, but if done properly it can be expanded greatly. The fact that the memory is all in one place means that it results in a <em>massive</em> reduction of cache misses, which on modern hardware translates to a whole lot of cycles. Your program will run a lot faster if it isn't spending half its execution time just waiting for memory.</p><p>Those of you who are still following this explanation may have an idea of where I'm going with this. To answer the problem of data locality and memory management in modern applications, we require an entirely new kind of memory management, one based around locality, not memory efficiency (although as we'll see later, the resulting allocator can actually succeed at being efficient at the same time).</p><p>We start with a simple concept - an allocator for a given class type. All classes are, by definition, the same size. This means that any allocator designed for a single class will be incredibly fast. Usually in this situation, a bucket based approach is ideal, since we want the data to be close together, but we don't want to be dealing with stupidly large chunks of memory either. However we must also take note of how important data locality is on modern hardware, so we want those buckets to be comparatively large. But then we have another problem - what if a given class is only instantiated once? The answer is to have a bucket size algorithm that looks something like this:</p><a href=http://img691.imageshack.us/img691/1508/memorygraph.png target=_blank><img src=http://img691.imageshack.us/img691/1508/memorygraph.png></a><p>Of course, this is made a lot easier if we know what the intended use of the class is in the first place. As long as the programmer tells the allocator how many classes of a given type to start with, we can skip to that amount on our allocation curve. Notice that at some point, the allocation curve flattens out to a 1:1 ratio, since if we're allocating anything larger the 32kb, its probably going to be something like 50 megs and should be delegated to the default memory allocator anyway.</p><p>Now we have an efficient method of building an allocator for a single type of class. But if we think about what we are actually doing here, an interesting optimization comes to mind. We are basing this allocator off 2 concepts: similar classes often end up being accessed often, and they are the same size.</p><p>Wait, <em>they're the same size</em>. What if we extended our concept such that if two classes are the same size, they get thrown into the <em>same allocator</em>? But we have a problem: going back to our original example, if we have a program-critical linked list that should obviously have a memory locale of its own in its own allocator or the entire point of reducing cache misses is lost. This is where we stumble on a very interesting concept: We allow the programmer to <em>define their own locality</em>.</p><p>What we do is have multiple allocators for each given class size. If we have several classes that are all 12 bytes (the sheer amount of classes that are 12 bytes is actually quite astounding), they'll be grouped into a single 12-byte bucket allocator. What happens is that we can assign an <strong>Index ID</strong> to this allocator. If a programmer has a class that he wants to have single allocator for, he can input an index ID of, for example, 12. This will cause another allocator to be created and used only for that class. However, we introduce the additional possibility of assigning an allocator for say, 2 or 3 classes. If they all have the same unique index ID, they'll be routed to the same allocator. This allows the programmer to have an unprecedented amount of control over data locality.</p><p>To complete our memory management pool, we require a global allocator to take care of our smaller allocators. The global allocator manages a gigantic pool of memory that is segmented into chunks for the various n-byte pools. When a new pool requires an amount of memory that is greater then the largest chunk available, the global allocator grabs another chunk from the default allocator. Furthermore, whenever this occurs, it triggers an optimization run on the memory pools. Empty buckets are freed and memory is moved where it is feasible. The global allocator will also need to pay attention to where the memory is freed so that, even if we have to allocate a giant chunk for some very large byte pool, we then have a bunch of memory that's available for less-used pools, again allowing us to avoid allocating additional memory. The combination of all 3 concepts allows a relatively efficient and super fast cache-aware memory allocator that can be implicitly built into any class by the inclusion of a very simple static template class. Almost everything can be done behind the scenes, and we never even overload the global new operator, since participating classes are marked (there are a buttload of reasons why we wouldn't want to overload the global new operator but I won't go into that here).</p><p>No tests of this system are available as I have not built it yet, but I will report on the results once I have them.</p></div><hr><time itemprop=datePublished pubdate=pubdate datetime=2009-12-05T16:28:00+00:00><i class="fa fa-clock-o fa-fw"></i>&nbsp;Published on <a href=https://erikmcclure.com/blog/memory-management-on-modern-cpus/>December 5, 2009 at 4:28pm</a></time><aside><i class="fa fa-share-square-o fa-fw"></i>&nbsp;share:<ul><li><a href="javascript:window.open('https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ferikmcclure.com%2fblog%2fmemory-management-on-modern-cpus%2f','popup','width=600,height=400');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" d="M16.75 9H13.5V7a1 1 0 011-1h2V3H14a4 4 0 00-4 4V9H8v3h2v9h3.5V12H16z"/></svg></a><li><a href="javascript:window.open('https://twitter.com/intent/tweet?text=Memory%20Management%20on%20Modern%20CPUs&url=https%3a%2f%2ferikmcclure.com%2fblog%2fmemory-management-on-modern-cpus%2f','popup','width=600,height=256');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><path class="st0" opacity="0" d="M0 0h24v24H0z"/><path class="st0" d="M23.643 4.937c-.835.37-1.732.62-2.675.733.962-.576 1.7-1.49 2.048-2.578-.9.534-1.897.922-2.958 1.13-.85-.904-2.06-1.47-3.4-1.47-2.572.0-4.658 2.086-4.658 4.66.0.364.042.718.12 1.06-3.873-.195-7.304-2.05-9.602-4.868-.4.69-.63 1.49-.63 2.342.0 1.616.823 3.043 2.072 3.878-.764-.025-1.482-.234-2.11-.583v.06c0 2.257 1.605 4.14 3.737 4.568-.392.106-.803.162-1.227.162-.3.0-.593-.028-.877-.082.593 1.85 2.313 3.198 4.352 3.234-1.595 1.25-3.604 1.995-5.786 1.995-.376.0-.747-.022-1.112-.065 2.062 1.323 4.51 2.093 7.14 2.093 8.57.0 13.255-7.098 13.255-13.254.0-.2-.005-.402-.014-.602.91-.658 1.7-1.477 2.323-2.41z"/></svg></a></li><li><a href="javascript:window.open('https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ferikmcclure.com%2fblog%2fmemory-management-on-modern-cpus%2f','popup','width=700,height=380');"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="twtr-icon twtr-color-fill--blue-dark has-hover"><style>.st0{fill:#666}</style><rect class="st0" height="11" width="4" x="3" y="9"/><circle class="st0" cx="5" cy="5" r="2"/><path class="st0" d="M16.5 8.25A4.47251 4.47251.0 0013 9.95343V9H9V20h4V13a2 2 0 014 0v7h4V12.75a4.5 4.5.0 00-4.5-4.5z"/></svg></a></li><li><a href="javascript:window.open('https://plus.google.com/share?app=110&url=https%3a%2f%2ferikmcclure.com%2fblog%2fmemory-management-on-modern-cpus%2f','popup','width=400,height=380');"><svg xmlns="http://www.w3.org/2000/svg" viewBox="4 2 52.6934 50.6934" class="icon-img" height="24"><style>.st0{fill:#666}</style><g><path class="st0" d="M19.6671 25.7867c-.0075 1.7935.0 3.5869.0076 5.3803 3.0067.098 6.0208.0527 9.0275.098-1.3262 6.6689-10.3989 8.8315-15.199 4.4761C8.5674 31.9206 8.801 23.5412 13.9327 19.992c3.5869-2.8635 8.6884-2.1552 12.2752.324 1.4092-1.3036 2.7278-2.6977 4.0013-4.1445-2.984-2.3812-6.6462-4.0767-10.5421-3.8958-8.1307-.2713-15.6059 6.8497-15.7415 14.9805-.52 6.6462 3.8506 13.1644 10.0222 15.5155 6.1489 2.3661 14.031.7535 17.957-4.77 2.5922-3.4889 3.1498-7.98 2.8484-12.1999C29.7194 25.7641 24.6933 25.7716 19.6671 25.7867z"/><path class="st0" d="M49.0704 25.7641c-.0151-1.4996-.0226-3.0067-.0301-4.5062-1.4996.0-2.9916.0-4.4836.0-.0151 1.4996-.0301 2.9991-.0377 4.5062-1.5071.0075-3.0067.0151-4.5062.0302.0 1.4995.0 2.9915.0 4.4836 1.4995.0151 3.0066.0302 4.5062.0452.0151 1.4996.0151 2.9991.0302 4.4987 1.4996.0 2.9916.0 4.4911.0.0075-1.4996.015-2.9991.0301-4.5062 1.5071-.0151 3.0067-.0226 4.5062-.0377.0-1.4921.0-2.9916.0-4.4836C52.0771 25.7792 50.57 25.7792 49.0704 25.7641z"/></g></svg></a></li></ul></aside></article><article><a name=comments><h4>Comments</h4></a><hr><div class=comments></div><div class=comments></div><div class=wrapcommento><div id=commento></div><script src=https://cdn.commento.io/js/commento.js></script></div></form></article></section><section class=archive><article><img src=https://erikmcclure.com/img/avatar.th.png alt=Avatar width=180 height=180><h2>Archive</h2><ol><li><details><summary>2020</summary><ul><li><a href=/blog/why-you-cant-use-prebuilt-llvm-with-cpp17/>Why You Can't Use Prebuilt LLVM 10.0 with C++17</a></li><li><a href=/blog/someone-is-stealing-tracker-songs/>Someone Is Stealing Tracker Songs And Selling Them</a></li><li><a href=/blog/pressure-based-anti-spam-for-discord-bots/>Pressure Based Anti-Spam for Discord Bots</a></li><li><a href=/blog/debugging-through-webassembly-is-impossible/>Debugging Through WebAssembly Is Impossible</a></li></ul></details></li><li><details><summary>2019</summary><ul><li><a href=/blog/name-shadowing-should-be-an-operator/>Name Shadowing Should Be An Operator</a></li><li><a href=/blog/a-rant-on-terra/>A Rant On Terra</a></li><li><a href=/blog/risc-is-fundamentally-unscalable/>RISC Is Fundamentally Unscalable</a></li></ul></details></li><li><details><summary>2018</summary><ul><li><a href=/blog/software-engineering-is-bad-but-it-s-not-that-bad/>Software Engineering Is Bad, But That's Not Why</a></li><li><a href=/blog/why-do-people-use-the-wrong-email-/>Why Do People Use The Wrong Email?</a></li><li><a href=/blog/software-optimizes-to-single-points-of-failure/>Software Optimizes to Single Points of Failure</a></li><li><a href=/blog/migrating-to-static-blog/>Migrating To A Static Blog</a></li><li><a href=/blog/how-to-avoid-memorizing-times-tables/>How To Avoid Memorizing Times Tables</a></li></ul></details></li><li><details><summary>2017</summary><ul><li><a href=/blog/ignoring-outliers-creates-racist/>Ignoring Outliers Creates Racist Algorithms</a></li><li><a href=/blog/i-used-to-want-to-work-for-google/>I Used To Want To Work For Google</a></li><li><a href=/blog/sexist-programmers-are-awful-engineers/>Sexist Programmers Are Awful Engineers</a></li><li><a href=/blog/why-i-never-built-my-soundcloud-killer/>Why I Never Built My SoundCloud Killer</a></li><li><a href=/blog/integrating-luajit-and-autogenerating-c/>Integrating LuaJIT and Autogenerating C Bindings In Visual Studio</a></li><li><a href=/blog/discord-rise-of-bot-wars/>Discord: Rise Of The Bot Wars</a></li><li><a href=/blog/programmers-should-take-linguistics/>Programmers Should Take Linguistics</a></li><li><a href=/blog/companies-cant-be-apolitical/>Companies Can't Be Apolitical</a></li><li><a href=/blog/i-cant-hear-anything-below-80-hz/>I Can't Hear Anything Below 80 Hz*</a></li><li><a href=/blog/windows-wont-let-my-program-crash/>Windows Won't Let My Program Crash</a></li><li><a href=/blog/owlboy-and-tragedy-of-human-nature/>Owlboy And The Tragedy of Human Nature</a></li><li><a href=/blog/directx-is-terrifying/>DirectX Is Terrifying</a></li><li><a href=/blog/our-software-is-beacon-of-hope/>Our Software Is a Beacon of Hope</a></li></ul></details></li><li><details><summary>2016</summary><ul><li><a href=/blog/everyone-does-srgb-wrong-because/>Everyone Does sRGB Wrong Because Everyone Else Does sRGB Wrong</a></li><li><a href=/blog/the-answer-is-not-more-censorship-its/>The Answer Is Not More Censorship, It's More Information</a></li><li><a href=/blog/mathematical-notation-is-awful/>Mathematical Notation Is Awful</a></li><li><a href=/blog/the-gpl-is-usually-overkill/>The GPL Is Usually Overkill</a></li><li><a href=/blog/the-right-to-ignore-difference-between/>The Right To Ignore: The Difference Between Free Speech And Harassment</a></li></ul></details></li><li><details><summary>2015</summary><ul><li><a href=/blog/there-will-never-be-one-true/>There Will Never Be One True Programming Language</a></li><li><a href=/blog/abortion-has-no-moral-high-ground/>Abortion Has No Moral High Ground</a></li><li><a href=/blog/i-tried-to-install-linux-and-now-i/>I Tried To Install Linux And Now I Regret Everything</a></li><li><a href=/blog/you-arent-designing-software-for-robots/>We Aren't Designing Software For Robots</a></li><li><a href=/blog/using-data-to-balance-your-game-pony/>Using Data To Balance Your Game: Pony Clicker Analysis</a></li><li><a href=/blog/is-there-commercial-open-source-license/>Is There A Commercial Open Source License?</a></li><li><a href=/blog/does-anyone-actually-want-good-software/>Does Anyone Actually Want Good Software?</a></li><li><a href=/blog/why-dont-you-just-fire-them/>Why Don't You Just Fire Them?</a></li></ul></details></li><li><details><summary>2014</summary><ul><li><a href=/blog/how-not-to-sell-software/>How Not To Install Software</a></li><li><a href=/blog/not-reinventing-wheel-is-anticompetitive/>Never Reinventing The Wheel Is Anticompetitive</a></li><li><a href=/blog/everyone-can-be-above-average/>Everyone Can Be Above Average</a></li><li><a href=/blog/what-use-is-good-job/>What Use Is A Good Job?</a></li><li><a href=/blog/can-we-choose-what-we-enjoy/>Can We Choose What We Enjoy?</a></li><li><a href=/blog/how-to-make-your-profiler-10x-faster/>How To Make Your Profiler 10x Faster</a></li><li><a href=/blog/fiction/>Fiction</a></li><li><a href=/blog/the-problem-with-photorealism/>The Problem With Photorealism</a></li><li><a href=/blog/success-is-relative/>Success Is Relative</a></li></ul></details></li><li><details><summary>2013</summary><ul><li><a href=/blog/my-steamos-experience/>My SteamOS Experience</a></li><li><a href=/blog/discrete-wavefront-propagation/>Tile-Based Discrete Wavefront Propagation</a></li><li><a href=/blog/googles-decline-really-bugs-me/>Google's Decline Really Bugs Me</a></li><li><a href=/blog/the-educational-imbroglio/>The Educational Imbroglio</a></li><li><a href=/blog/the-ladder-climbing-generation/>The Ladder-Climbing Generation</a></li><li><a href=/blog/the-microsoft-word-problem/>The Microsoft Word Problem</a></li><li><a href=/blog/write-less-code/>Write Less Code</a></li><li><a href=/blog/most-people-have-shitty-computers/>Most People Have Shitty Computers</a></li><li><a href=/blog/leap-motion-impressions-input/>Leap Motion Impressions, Input Sanitation, and 3D Gesture Ideas</a></li><li><a href=/blog/aurora-theory-released/>Aurora Theory Released!</a></li><li><a href=/blog/what-i-learned-in-college/>What I Learned In College</a></li><li><a href=/blog/how-to-complain-about-men-and-be-sexist/>How To Complain About Men And Be Sexist At The Same Time</a></li><li><a href=/blog/course-notes/>Course Notes</a></li><li><a href=/blog/contact/>Contact</a></li><li><a href=/blog/the-dark-side-of-htmlcss/>The Dark Side of Web Development</a></li><li><a href=/blog/windows-breaks-assert-inside/>Windows Breaks assert() Inside WM_CANCELMODE</a></li><li><a href=/blog/dreams-are-worth-fighting-for/>Dreams Are Worth Fighting For</a></li><li><a href=/blog/the-productivity-fallacy/>The Productivity Fallacy</a></li><li><a href=/blog/the-earbud-loudness-wars/>The Earbud Loudness Wars</a></li></ul></details></li><li><details><summary>2012</summary><ul><li><a href=/blog/giant-list-of-free-samples/>Giant List of FREE SAMPLES</a></li><li><a href=/blog/the-weekend-apelsin-got-lost-all-time/>The Weekend I Got Lost All The Time</a></li><li><a href=/blog/today-i-was-mistaken-for-17-year-old/>Today I Was Mistaken For A 17-Year-Old Girl</a></li><li><a href=/blog/c-to-c-tutorial-part-4-operator-overload/>C# to C++ Tutorial - Part 4: Operator Overload</a></li><li><a href=/blog/lockless-lattice-based-computing/>Lockless Lattice-Based Computing</a></li><li><a href=/blog/7-problems-raytracing-doesnt-solve/>7 Problems Raytracing Doesn't Solve</a></li><li><a href=/blog/teenage-rebellion-as-failure-of-society/>Teenage Rebellion as a Failure of Society</a></li><li><a href=/blog/analyzing-xkcd-click-and-drag/>Analyzing XKCD: Click and Drag</a></li><li><a href=/blog/what-is-right-answer/>What Is A Right Answer?</a></li><li><a href=/blog/coordinate-systems-and-cascading/>Coordinate Systems And Cascading Stupidity</a></li><li><a href=/blog/how-joysticks-ruined-my-graphics-engine/>How Joysticks Ruined My Graphics Engine</a></li><li><a href=/blog/properly-dreaming-about-success/>Properly Dreaming About Success</a></li><li><a href=/blog/multithreading-problems-in-game-design/>Multithreading Problems In Game Design</a></li><li><a href=/blog/ip-law-makes-you-asshole/>IP Law Makes You an Asshole</a></li><li><a href=/blog/stop-following-rules/>Stop Following The Rules</a></li><li><a href=/blog/standards-problem/>The Standards Problem</a></li><li><a href=/blog/an-evidence-based-refutation-of-the-project-glass-parodies/>An evidence-based refutation of the Project Glass parodies</a></li><li><a href=/blog/language-wars-are-pointless/>Language Wars Are Pointless</a></li><li><a href=/blog/why-windows-8-does-right-thing-wrong/>Why Windows 8 Does The Right Thing The Wrong Way</a></li><li><a href=/blog/well-that-was-interesting/>Well That Was Interesting</a></li><li><a href=/blog/visual-studio-broke-my-computer/>Visual Studio Broke My Computer</a></li><li><a href=/blog/success-is-not-what-you-think-it-is/>Success Is Not What You Think It Is</a></li><li><a href=/blog/hiring-wrong-people/>Hiring the Wrong People</a></li><li><a href=/blog/chill-out/>Chill Out</a></li><li><a href=/blog/implicit-ui-design/>Implicit UI Design</a></li><li><a href=/blog/linux-mint-12-kde/>Linux Mint 12 KDE</a></li><li><a href=/blog/new-post/>'Programmer' is an Overgeneralization</a></li><li><a href=/blog/wikipedias-identity-crisis/>Wikipedia's Identity Crisis</a></li></ul></details></li><li><details><summary>2011</summary><ul><li><a href=/blog/your-esoteric-language-is-useless/>Your Esoteric Language is Useless</a></li><li><a href=/blog/great-mystery-of-linear-gradient/>The Great Mystery of Linear Gradient Lighting</a></li><li><a href=/blog/signed-integers-considered-stupid-like/>Signed Integers Considered Stupid (Like This Title)</a></li><li><a href=/blog/why-kids-hate-math/>Why Kids Hate Math</a></li><li><a href=/blog/importance-of-importance/>Don't Work on Someone Else's Dream</a></li><li><a href=/blog/c-to-c-tutorial-part-3-classes-and/>C# to C++ Tutorial - Part 3: Classes and Structs and Inheritance (OH MY!)</a></li><li><a href=/blog/problem-of-vsync/>The Problem of Vsync</a></li><li><a href=/blog/musical-genres/>Musical Genres</a></li><li><a href=/blog/c-to-c-tutorial-part-2-pointers/>C# to C++ Tutorial - Part 2: Pointers Everywhere!</a></li><li><a href=/blog/radians-explanation/>Radians: An explanation</a></li><li><a href=/blog/c-to-c-tutorial-part-1-basics-of-syntax/>C# to C++ Tutorial - Part 1: Basics of Syntax</a></li><li><a href=/blog/on-hackers/>On Hacking (or Why We Need Security Ratings)</a></li><li><a href=/blog/my-mom-had-heart-attack/>My Mom Had a Heart Attack</a></li><li><a href=/blog/religion-problem-perspectives/>The Religion Problem: Perspectives</a></li><li><a href=/blog/genetic-game-generation/>Genetic Game Generation</a></li><li><a href=/blog/ninth-circle-of-bugs/>The Ninth Circle of Bugs</a></li><li><a href=/blog/save-rss/>Save RSS</a></li><li><a href=/blog/college-is-broken/>College Is Broken</a></li><li><a href=/blog/outside-perspective-on-psn-fiasco/>An Outside Perspective on the PSN Fiasco</a></li><li><a href=/blog/future-predictions/>Future Predictions</a></li><li><a href=/blog/investigating-low-level-cpu-performance/>Investigating Low-level CPU Performance</a></li><li><a href=/blog/bullying-never-stops/>The Bullying Never Stops</a></li></ul></details></li><li><details><summary>2010</summary><ul><li><a href=/blog/aquaria-hints/>Aquaria Hints</a></li><li><a href=/blog/im-failure/>The IM Failure</a></li><li><a href=/blog/how-to-train-your-dragon/>How To Train Your Dragon</a></li><li><a href=/blog/album-for-sale-renascent/>Album For Sale! [Renascent]</a></li><li><a href=/blog/wavsaver/>WavSaver</a></li><li><a href=/blog/pixel-perfect-hit-testing/>Pixel Perfect Hit Testing</a></li><li><a href=/blog/fractal-cycle-screensaver/>Fractal Cycle Screensaver</a></li><li><a href=/blog/8-bit-color-cycling/>8-bit color cycling</a></li><li><a href=/blog/physics-networking/>Physics Networking</a></li><li><a href=/blog/assembly-cas-implementation/>Assembly CAS implementation</a></li><li><a href=/blog/desktop-composition/>Desktop Composition</a></li><li><a href=/blog/function-pointer-speed/>Function Pointer Speed</a></li><li><a href=/blog/most-bizarre-error-ever/>Most Bizarre Error Ever</a></li><li><a href=/blog/multithreading/>Multithreading</a></li><li><a href=/blog/floating-point-preformance/>Floating Point Preformance</a></li><li><a href=/blog/volumetric-rendering-in-realtime/>Volumetric Rendering in Realtime</a></li><li><a href=/blog/watch-this-now/>Watch This Now</a></li><li><a href=/blog/extraordinary/>Extraordinary</a></li></ul></details></li><li><details><summary>2009</summary><ul><li><a href=/blog/memory-management-on-modern-cpus/>Memory Management on Modern CPUs</a></li><li><a href=/blog/posted-while-on-bus/>Posted While On A Bus</a></li><li><a href=/blog/physics-oriented-network-interpolation/>Physics-oriented Network Interpolation</a></li><li><a href=/blog/nearest-neighbor-algorithms-for-2d-and/>Nearest Neighbor Algorithms for 2D and 3D lighting</a></li><li><a href=/blog/proving-strong-ai/>Proving Strong AI</a></li><li><a href=/blog/optimal-open-source-licenses/>Optimal Open-Source Licenses</a></li><li><a href=/blog/i-now-have-lj/>I now have an LJ</a></li></ul></details></li></ol></article></section></main><footer><p><span>Copyright &copy;2020 Erik McClure</span> <a href=https://erikmcclure.com/sitemap.xml>Sitemap</a> | <a href=https://erikmcclure.com/blog/index.xml>RSS Feed</a></p></footer></div><script>"use strict";window.onload=function(){var t=document.getElementsByClassName('math');for(var i=0,len=t.length;i<len;i++){renderMathInElement(t[i],{delimiters:[{left:"$$",right:"$$",display:false},{left:"\\[",right:"\\]",display:true}]});}}</script></body></html>