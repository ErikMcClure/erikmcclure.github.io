+++
categories = ["blog"]
date = ""
draft = true
title = "RISC Is Fundamentally Unscalable"

+++
Today, there was an announcement about [a new RISC-V chip](https://twitter.com/Calista_Redmond/status/1154278392344305664), which has got a lot of people excited. I wish I could also be excited, but to me, this is just a reminder that RISC architectures are fundamentally unscalable, and inevitably stop being RISC as soon as they need to be fast. People still call ARM a "RISC" architecture despite [ARMv8.3-A adding a `FJCVTZS` instruction](https://en.wikipedia.org/wiki/ARM_architecture#ARMv8.3-A), which is "Floating-point Javascript Convert to Signed fixed-point, rounding toward Zero". Reduced instruction set, my ass.

The reason this keeps happening is because **the laws of physics** ensure that no RISC architecture can scale under load. The problem is that a modern CPU is so fast that just accessing the L1 cache takes anywhere from [3-5 cycles](https://www.7-cpu.com/cpu/Skylake_X.html). This is part of the reason modern CPUs rely so much on [register renaming](https://en.wikipedia.org/wiki/Register_renaming), allowing them to have hundreds of internal registers that are used to make things actually go fast, as opposed to the paltry [90 general purpose registers actually exposed](https://en.wikipedia.org/wiki/X86#/media/File:Table_of_x86_Registers_svg.svg), 40 of which are just floating point registers for vector operations. The fundamental issue that CPU architects run into is that **the speed of light isn't getting any faster**. Even getting an electrical signal from one end of a CPU to the other now takes more than one cycle, which means the physical layout of your CPU now has a significant impact on how fast operations take. Worse, the faster the CPU gets, the more this lag becomes a problem, so unless you shrink the entire CPU or redesign it so your L1 and L2 caches are *physically closer to the transistors that need them*, the latency from accessing those caches can only go up, not down. The CPU might be getting faster, but the speed of light isn't.

Now, obviously RISC CPUs are very complicated architectures that do [all sorts of insane pipelining](https://en.wikipedia.org/wiki/Classic_RISC_pipeline#Hazard) to try and execute as many instructions at the same time as possible. This is necessary because, unless your data is already loaded into registers, you might spend more cycles *loading data from the L1 cache* than doing the actual operation! If you're data is in L2 cache, you might as well go get lunch, because 